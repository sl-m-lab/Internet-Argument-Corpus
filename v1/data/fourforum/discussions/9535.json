[
 [
  [
   249849, 
   null, 
   "wascallywabbit", 
   "**\n \n As a thread starter--\n \n \"\"EVOLUTION AND LEARNING: The Baldwin Effect Reconsidered\",\n \n Bruce Weber and Devide Depew (eds.), MIT Press, 2003, pp. 253-272\n \n 1. Introduction\n \n That the species of this world are products of evolution is a fact we no longer have to defend, and thus we no longer need to agree on some unitary simple mechanism to justify its belonging inside well established scientific knowledge. Rather we should try to grasp the evolutionary process on Earth as a multifaceted play of creative life processes. That such a process has ultimately created intelligence is a striking fact, which is not easily explained in the absence of a theory of natural intentionality ('aboutness'). Biosemiotics, by positing interpretation in the center of its focus, necessarily admits semiosis as an inescapable feature of life and claims that semiosis (i.e., sign action[i], see below) was the root-form of intentionality and intelligence. Biosemiotics shares with Baldwinism an ambition to widening up evolutionary theory by putting explicit emphasis on the influence of mental processes in the broadest sense possible of this term, i.e. as comprising semiotic interactions even at the cellular level.\"\n \n see complete paper at---\n \n http://www.imbf.ku.dk/MolBioPages/abk/PersonalPages/Jesper/Baldwinism.html", 
   {
    "post_info": {
     "post_title": "Intelligent evolution--Semiotics and the &quot;Baldwin effect&quot;."
    }
   }, 
   null, 
   null, 
   1170783600.0
  ], 
  [
   249862, 
   null, 
   "SLP", 
   "I read it.\n \n I don't think it means what you want it to.", 
   {}, 
   249849, 
   null, 
   1170787680.0
  ], 
  [
   249891, 
   null, 
   "wascallywabbit", 
   "**\n Excerpt--\n \n \"Phenotypic plasticity, parental effects, and parental care in plants? I. An examination of spike reflectance in Plantago lanceolata (Plantaginaceae)\"1 \n Elizabeth P. Lacey2 and David Herr \n \n \"In a fourth experiment, we measured internal spike temperature. Darker spikes, those produced at lower temperature, got hotter than did lighter spikes in full sun. Thus, plants can partially thermoregulate reproduction and the embryonic development of their offspring. In light of a previous experiment, data suggest that thermoregulation produces adaptive parental effects and is a mechanism by which P. lanceolata provides parental care.\"\n \n Who knew?!\n \n from--\n http://www.amjbot.org/cgi/content/full/92/6/920", 
   {}, 
   249862, 
   null, 
   1170796080.0
  ], 
  [
   249898, 
   null, 
   "wascallywabbit", 
   "**\n \n excerpt--\n \n \"EPIGENESIS refers to the influence of the environment on the expression of the genetic code. Many genes require specific environmental circumstances in order to be expressed; many genes are never expressed. The genetic \"program\" refers to the potential for initiating and orchestrating specific physiological processes that MAY ultimately manifest themselves in a trait such as behavior. \n \n \n Genes always interact (more-or-less) with their environments and in animals such as humans it begins at conception: Some comments by a corresponding colleague, Ross Buck (May 6, 2005): \"Again the notion of heritability is being presented as a meaningful measure of genetic-versus-environmental influence. Most monozygotic twins are monochorionic, sharing the same choroid plexus and therefore the same blood supply in the womb. A minority are dichorionic, with identical genes but a different intrauterine blood supply. Davis, Phelps and Bracha (Schizophrenia Bulletin, 1995, 21, 357-366) investigated concordance of schizophrenia in monochorionic and dichorionic monozygotic twins, and found that while the concordance rate for MC MZ twins was 60% (i.e., if one twin is schizophrenic there is a 60% chance the other will be as well), the concordance rate of the DC MZ twins (with identical genes) was 10.7%. Environmental influences are overwhelming, and they begin at conception: the genes do nothing without environmental influences turning them on and off.\" \n \n . . \n \" Epigenetic inheritance is when information is transmitted to subsequent generations that does not involve changes in the sequences of DNA -- Gene expression can be modulated without actually changing the DNA by methylation (which usually silences genes) or any of several other possible ways of changing the ease with which the environment can activate a specific gene. In some ways, transmission of constraints in genetic expression (even if DNA is not changed) resembles Lamarckian \"transmission of acquired characteristics\" --generally regarded as an implausible hypothesis because it seemed to rely on changes in the genetics code, BUT selective expression of that code is in many ways functionally similar! The genome, to include these constraints is sometimes termed the \"epigenome.\"\n \n at--\n \n https://notes.utk.edu/bio/greenberg.nsf/dce24a98e9f73ba785256d270039a9de/f0820b0a18b7994185256d270047a586?OpenDocument", 
   {
    "unicode_changes_made": true
   }, 
   249862, 
   null, 
   1170797040.0
  ], 
  [
   249913, 
   null, 
   "supersport", 
   "WW....I haven't read much about it, but I thought the baldwin effect was an evolutionist mechanism in that it included natural selection.", 
   {}, 
   249898, 
   null, 
   1170801720.0
  ], 
  [
   249923, 
   null, 
   "wascallywabbit", 
   "WW....I haven't read much about it, but I thought the baldwin effect was an evolutionist mechanism in that it included natural selection.\n\n \n **\n Just after Darwin's death the holes in the theory of evolution by natural selection were threatening to destroy it. Neo-darwinians cast about for ways to combat a resurgent neo-lamarckism in an attempt to show where the variations that NS supposedly chose from originated. Darwin had already borrowed his 'pangenesis' from Lamarck by simply rephrasing it, and Baldin did the same thing, at the same time inserting a 'selection' mechanism into the mix, in order to make a Lamarckian principle look neo-darwinian. Thus--\n \n \"Baldwin effect\n From Wikipedia, the free encyclopedia\n \n The Baldwin effect, also known as Baldwinian evolution or ontogenic evolution, is an early evolutionary theory proposed by American psychologist James Mark Baldwin which proposes a mechanism for specific selection for general learning ability. Selected offspring would tend to have an increased capacity for learning new skills rather than being confined to genetically coded, relatively fixed abilities. In effect, it places emphasis on the fact that the sustained behavior of a species or group can shape the evolution of that species.\n \n In 1896, Baldwin proposed that individual learning can explain evolutionary phenomena that appear to support Lamarckian inheritance. He saw the Baldwin Effect, which he called organic selection, as a reconciliation between Lamarckian evolution and Darwinian evolution. It proposed that the ability of individuals to learn can guide the evolutionary process, facilitating evolution by smoothing the fitness landscape. Baldwin further proposed that abilities that initially require learning are eventually replaced by the evolution of genetically determined systems that do not require learning. Thus learned behaviors may become instinctive behaviours in subsequent generations, without invoking the discredited Lamarckian inheritance. Unlike Lamarckian evolution, it does not involve direct transfer of learned abilities from generation to generation.\n \n As an example, suppose a species is threatened by a new predator and there is a behavior that makes it more difficult for the predator. Individuals who learn the behavior more quickly will obviously be at an advantage. As time goes on the ability to learn the behavior will improve (by genetic selection), and at some point it will seem to be an instinct.\"\n \n **\n All you have to do is re-insert \"direct transfer of learned abilities from generation to generation\", (along with the morphological changes arising from those new behaviours), and you are right back to lamarckian evolution, no 'natural selection' required. Point out that the \"direct transfer of learned abilities from generation to generation\" is now called 'developmental evolution', and you are talking EAM.", 
   {}, 
   249913, 
   null, 
   1170805560.0
  ], 
  [
   250131, 
   null, 
   "SLP", 
   "I am sure some are impressed with post-keyword search cut and pastes, but I am more interested in hearing your interpretations and explanations of these things.\n \n I know you are maturely just ignoring me and hoing that your spamming impresses readers into thinking you are onto something, but I think the more intelligent out there see a pattern evolving.", 
   {}, 
   249923, 
   null, 
   1170869940.0
  ], 
  [
   250153, 
   null, 
   "wascallywabbit", 
   "**\n Excerpt--\n \n \"MICROBIAL AND PLANT MULTILEVEL COMMUNICATION\"\n \n \"Communication is the key element in successful organization\" (Kolenbrander et al., 2002: 486). The coordinated community, for example of oral bacteria in humans, relies on intra- and interspecies communication. This community encompasses ca. 500 different species, some of which cooperate, others which compete (Kolenbrander et al., 2002). The complexity of potential interactions in the oral cavity and the number of possibilities reach unimaginable proportions if we assume that each of the 500 bacteria species can regulate its genes in response to host-produced molecules and interacts with all the other bacteria species (Kolenbrander et al., 2002).\n \n Highly complex interspecies communication enables bacteria species to communicate even in special sites of hosts such as the gastrointestinal tract, where they can gauge their population sizes by exchanging molecules despite the incredible number of similar molecules surrounding them. Even in such critical situations, the species can reliably differentiate between population-specific (interorganismic) signals, foreign signals and \"noise\" (Federle and Bassler, 2003).\n \n The microbiological community is exposed to a broad range of chemical substances in which an incredible variety of chemical messenger substances is embedded, from which they must be able to take up and interpret the correct ones in order to survive. It is very difficult to imagine how bacteria can differentiate between sense and nonsense in their chemical environment, in which they are constantly bombarded from all sides by small molecules (Dunn and Handelsman, 2002).\n \n The discovery of species-specific and trans-specific signal molecules reveals an unexpectedly highly developed communication. In nature, where bacteria typically live together with numerous other species, signal molecules allow them to determine how large their populations are, how many other communities are present and their sizes, and to respond appropriately to this information by adapting their gene expression (Federle and Bassler, 2003).\n \n This discovery has led to the suggestion that under real-life conditions, microorganisms must simultaneously be able to conduct many molecular conversations with different types of organisms and even organismic kingdoms (Dunn and Handelsman, 2002). \"Using these advanced linguistic capabilities, bacteria can lead rich social lives for the group benefit. They can develop collective memory, use and generate common knowledge, develop group identity, recognize the identity of other colonies, learn from experience to improve themselves, and engage in group decision-making, an additional surprising social conduct that amounts to what should most appropriately be dubbed as social intelligence\" (Ben Jacob et al., 2004).\n \n The communicative abilities of bacteria are also present in symbiogenetically derived higher eukaryotes such as plants. The rhizosphere of plants is a realm of overlapping communicative interactions (Yoder, 1999; Walker et al., 2003; Bais et al., 2004; Baluska et al., 2005). The rhizosphere is a dynamic environment featuring dense microbiological life, high growth rates and metabolic activities, as well as rapidly changing physical conditions (Dessaux, 2004). Most of the decisions that plants make regarding their growth and development involve communication processes between all parts of the plant and works as neuronal communication (Dustin et al., 2001; Roshchina, 2001; Trewavas, 2003; Davies, 2004; Baluska et al., 2005). Learning and memory are two characteristic features for neuronal networks that require a large number of nerve cells to communicate with one another. Interestingly, nerve cells and plant cells use very similar sequences of signal molecules so that we speak today of neuronal communication in plant neurobiology, not any longer of the dominant role of action potentials in plant physiology (Trewavas, 2003; Baluska, 2004; Davies. 2004; Baluska et al., 2005).\n \n The communication processes between tissues and cells in plants is incredibly complex and encompasses nucleic acids, oligonucleotides, proteins and peptides, minerals, oxidative signals, gases, mechanical signals, electrical signals, fatty acids, and oligosaccharides, growth factors, several amino acids, various secondary products and simple sugars (Trewavas, 2003).\n \n Communication, i.e. rule governed sign mediated interactions, is indispensable for the normal development of cells, tissues, organs and bodies (Witzany, 2005). They (rsi) control movement and coordinated behaviour, developmental stages in time, symbiotic interactions as well as defence strategies. Associated cells require a precise coordination in sending and receiving signals. Disturbance of rule-governed sign-mediated interactions lead to pathological situations ranging from abnormal cell proliferation to cell death (Perbal, 2003).\n \n As in every biosemiotic process of real lifeworld (pragmatic) situations, context determines semantic meaning of signals. Auxin, for example, is an ancient signalling molecule in plants. Since it functions in different hormonal, morphogen and transmitter signalling pathways, it is very difficult to decipher the actual semantics of Auxin which depends on whether it is used as hormonal or morphogen or transmitter signal (Baluska et al., 2005: 108). Because the same signal can take on different meanings and trigger different effects, depending on whether it reaches the whole plant, a tissue or a cell, the respective developmental status of the organism serves as a memory for each individual plant. The individual plant is a complex multicellular and multi-tissue organism in which development is a permanent process and in which communication is the driving force (Trewavas, 2003): \n \n \"Biologists suggest that intelligence encompasses the characteristics of detailed sensory perception, information processing, learning, memory, choice, efficient optimisation of resource sequestration with minimal outlay, self-recognition, and foresight by predictive modelling. There is good evidence that individual plant species exhibit all of these intelligent behavioural capabilities\" (Trewavas, 2005).\"\n \n **\n at--\n http://www.library.utoronto.ca/see/SEED/Vol5-1/Witzany.htm\n \n Hopefully this well draw an intelligent and cogent response for a change.", 
   {
    "unicode_changes_made": true
   }, 
   250131, 
   null, 
   1170875460.0
  ], 
  [
   250185, 
   null, 
   "runtym", 
   "Hi WW,\n \n I'm not a scientist, so I was wondering if you could explain those quotes and such for me.\n \n Thanks.", 
   {}, 
   250153, 
   null, 
   1170882360.0
  ], 
  [
   250198, 
   null, 
   "wascallywabbit", 
   "Hi WW,\n \n I'm not a scientist, so I was wondering if you could explain those quotes and such for me.\n \n Thanks.\n\n \n **\n Glad to, provided you quote the passage giving you trouble and state your problem in comprehending it. Please don't ask about particular words unless you feel that they are not being used in any way given by a dictionary.", 
   {}, 
   250185, 
   null, 
   1170887820.0
  ], 
  [
   250219, 
   null, 
   "runtym", 
   "**\n Glad to, provided you quote the passage giving you trouble and state your problem in comprehending it. \n\n My problem is not in general comprehension, it is in how any of what you cut and pasted indicates EAM. I do not see how anything you posted in this thread does. Maybe you can just sunmmarize? You present these long quotes and provide no commentary or summary or interpretation, and when I read through them, they seem interesting as stand alone items, but given your advocacy for EAM I assume that they are presented as some sort of support for that unless otherwise indicated. And that is the part I am having trouble with.\n\n Please don't ask about particular words unless you feel that they are not being used in any way given by a dictionary.\n\n I have found that dictionaries are not usually helpful when trying to understand how particular terms are used in specialized fields of study.", 
   {}, 
   250198, 
   null, 
   1170894000.0
  ], 
  [
   250223, 
   null, 
   "GazzaElliott", 
   "I have found that dictionaries are not usually helpful when trying to understand how particular terms are used in specialized fields of study.\n\n \n Beware lest you provoke the wrath of the wabbit, in his sworn mission to defend the Eengleesh language from all technical specification, apart from when he's the one specifying it!", 
   {}, 
   250219, 
   null, 
   1170894780.0
  ], 
  [
   250228, 
   null, 
   "wascallywabbit", 
   "My problem is not in general comprehension, it is in how any of what you cut and pasted indicates EAM. I do not see how anything you posted in this thread does.\n\n \n **\n That's probably due to your ignorance of Endogenous Adaptive Mutagenesis Theory. In which case all you have to do is specify a certain passage and ask how it relates to EAM.\n \n \n\n Maybe you can just sunmmarize?\n\n \n Summarize what? EAM? Sure. EAM is a theoretical explanation for the historical process of organismic evolution which places the power and ability to evolve within the live organism itself, as a dynamic, self-organizing, self-directing, self-serving, complex, information-dependent, autopoietic system.\n \n \n\n You present these long quotes and provide no commentary or summary or interpretation, and when I read through them, they seem interesting as stand alone items, but given your advocacy for EAM I assume that they are presented as some sort of support for that unless otherwise indicated. And that is the part I am having trouble with.\n\n \n **\n Well, you aren't going to be able to digest their meaning unless you chew on the bits. Be specific and I'll take your questions one at a time. But do not expect me to convince you of anything. You can simply gainsay anything I say, as is the accepted practice among darwindefenders, and that's fine by me. I'm not going to argue attitudes.\n \n \n\n I have found that dictionaries are not usually helpful when trying to understand how particular terms are used in specialized fields of study.\n\n \n **\n Which should tell you to watch out for the con the wiseguys in those \"specialized fields of study\" are trying to pull on you. If you check, you'll find that word usage in most sciences corresponds closely to common usage. \"Special meanings\" are mostly confined to biology, more particularly, evolutionary biology, most particularly the RMNS darwinist notion of evolutionary biology.", 
   {}, 
   250219, 
   null, 
   1170896640.0
  ], 
  [
   250233, 
   null, 
   "GazzaElliott", 
   "Which should tell you to watch out for the con the wiseguys in those \"specialized fields of study\" are trying to pull on you. If you check, you'll find that word usage in most sciences corresponds closely to common usage. \"Special meanings\" are mostly confined to biology, more particularly, evolutionary biology, most particularly the RMNS darwinist notion of evolutionary biology.\n\n \n Watch your step runtym. Beware of the bull****.", 
   {}, 
   250228, 
   null, 
   1170897360.0
  ], 
  [
   250242, 
   null, 
   "electrolyte", 
   "Summarize what? EAM? Sure. EAM is a theoretical explanation for the historical process of organismic evolution which places the power and ability to evolve within the live organism itself, as a dynamic, self-organizing, self-directing, self-serving, complex, information-dependent, autopoietic system.\n\n ... which you \"justify\" by likening adaptedness to \"negentropy.\" However, as you painstakingly made clear, your \"entropy\" has nothing to do with thermodynamics, therefore negating the \"justification\" (second law of thermodynamics) behind the claim. When you were called on this, you ran away.\n \n \nWatch your step runtym. Beware of the bull****.\n\n And evasion.", 
   {}, 
   250233, 
   null, 
   1170898800.0
  ], 
  [
   250251, 
   null, 
   "wascallywabbit", 
   "... which you \"justify\" by likening adaptedness to \"negentropy.\" \n\n \n **\n Not true. Please quote the passage that leads you to believe that I said that \"adaptedness\" equates to \"negentropy\".\n \n \n\n However, as you painstakingly made clear, your \"entropy\" has nothing to do with thermodynamics,\n\n \n **\n Thermodynamic entropy applies only to matter in motion. Wherever in an organism matter is in motion, it applies, as such. I have not denied that. What I have said is that in information-driven complex autopoietic systems, that structural co-ordination, organization, interconnectedness, and communication generate adaptedness, in opposition to thermodynamic entropy. Since these design properties are dependent upon Vitality, you may assume that I see Vitality as negentropic.The entropy involved in that process is informational, not thermodynamic. What my link referred to as 'cognitive entropy', I believe. I prefer 'semiotic entropy', as I told you then.\n \n And since you realize that the entropy I'm talking about wrt living organismic biosystems is not the thermodynamic entropy of mechanical systems, why do you keep harping on it? Unable to accept that thermodynamic entropy is not the only entropy in the universe?\n \n \n\n therefore negating the \"justification\" (second law of thermodynamics) behind the claim. When you were called on this, you ran away.\n\n \n \n **\n I did not \"run away\". I had made my point. Conversation over. You're just too close-minded to realize that your opinions are antiques.", 
   {}, 
   250242, 
   null, 
   1170900960.0
  ], 
  [
   250253, 
   null, 
   "electrolyte", 
   "Not true. Please quote the passage that leads you to believe that I said that \"adaptedness\" equates to \"negentropy\".\n\n Did I say \"equates\"? No. I said that you liken the two. You insist that adaptedness cannot increase without an outside force a la the second law of thermodynamics.\n \n \nAnd since you realize that the entropy I'm talking about wrt living organismic biosystems is not the thermodynamic entropy of mechanical systems, why do you keep harping on it? Unable to accept that thermodynamic entropy is not the only entropy in the universe?\n\n What I realize is that your use of the word \"entropy\" has nothing to do with real entropy. This means that the second law of thermodynamics doesn't apply to it, so the claim that adaptedness cannot increase spontaneously is unfounded.\n \n \nI did not \"run away\". I had made my point. Conversation over.\n\n Uh, do you have a revisionist complex or something? After getting you to finally explain that your \"entropy\" isn't even the statistical application of scientific entropy, I pointed out that its status as such disjoins it from any rationale you have for believing that it cannot decrease. You didn't respond. At that point, the conversation was over...", 
   {}, 
   250251, 
   null, 
   1170901620.0
  ], 
  [
   250262, 
   null, 
   "wascallywabbit", 
   "Did I say \"equates\"? No. I said that you liken the two. You insist that adaptedness cannot increase without an outside force a la the second law of thermodynamics.\n\n \n **\n You say \"liken to\", I say \"equates\". Enjoy playing mindless word games, don't you?\n \n \n\n What I realize is that your use of the word \"entropy\" has nothing to do with real entropy. \n\n \n **\n \"Real entropy\". Hmm. Who went on and on about the \"no true scotsman\" fallacy. Sorry, chumly, but you don't get to say what is 'real' entropy' and what is 'false' entropy.\n \n \n\n This means that the second law of thermodynamics doesn't apply to it, so the claim that adaptedness cannot increase spontaneously is unfounded.\n\n \n **\n Wow. Now there's an industrial strength non sequitur as ever was!\n \n \n\n Uh, do you have a revisionist complex or something? \n\n \n **\n Nope. Do you have the snarky, sneering, sarcastic, demeaning schoolteacher complex? If you talk to kids the way you talk to people on this board, you should be fired, IMHO.\n \n \n\n After getting you to finally explain that your \"entropy\" isn't even the statistical application of scientific entropy,\n\n \n **\n You never \"finally got [me] to explain\" anything. I told you right from the jump that I was NOT referring to thermodynamic entropy.\n \n \n\n I pointed out that its status as such disjoins it from any rationale you have for believing that it cannot decrease.\n\n \n **\n You never \"point out\" anything. You simply make assertions that have no foundation or validity. And where does this, \"rationale you have for believing that it cannot decrease\", come from?!? Mind telling the world what the heck you think you're talking about?\n \n \n \n\n You didn't respond. At that point, the conversation was over...\n\n \n **\n Nah. The conversation was already over. As always, you didn't realise that.", 
   {}, 
   250253, 
   null, 
   1170906960.0
  ], 
  [
   250269, 
   null, 
   "Hi_Its_Me", 
   "**\n You say \"liken to\", I say \"equates\". Enjoy playing mindless word games, don't you?\n\n I would imagine that you do, especially if you want to give your argument an extra boost. Try making your previous point using the words \"liken to.\"\n \n**\n \"Real entropy\". Hmm. Who went on and on about the \"no true scotsman\" fallacy. Sorry, chumly, but you don't get to say what is 'real' entropy' and what is 'false' entropy.\n\n But, as has been made clear (or so we thought) to you already, entropy can increase unless it is defined in the same way as the 2lot states it.\n \n**\n You never \"point out\" anything. You simply make assertions that have no foundation or validity. And where does this, \"rationale you have for believing that it cannot decrease\", come from?!? Mind telling the world what the heck you think you're talking about?\n\n There is no reason why \"information\" cannot randomly increase. The only accurate statement that \"entropy cannot decrease\" is known as the Second Law of Thermodynamics. No others have been tested or are in any way supported by experimentation, and you can't (logically) claim otherwise.", 
   {}, 
   250262, 
   null, 
   1170909060.0
  ], 
  [
   250272, 
   null, 
   "electrolyte", 
   "You say \"liken to\", I say \"equates\". Enjoy playing mindless word games, don't you?\n\n Liken to means to show as similar -- to compare -- not show as identical.\n \n \n\"Real entropy\". Hmm. Who went on and on about the \"no true scotsman\" fallacy. Sorry, chumly, but you don't get to say what is 'real' entropy' and what is 'false' entropy.\n\n Of course I don't get to make the determination (I don't get to decide the laws of the universe), but I'm certainly qualified to make the distinction. I'm equally qualified to point out that your brand of \"entropy\" isn't governed by the second law of thermodynamics. You seem to be the only one who doesn't recognize this... else you do and simply won't admit its devastating effect on your argument.\n \n \nWow. Now there's an industrial strength non sequitur as ever was!\n\n Your inability to comprehend it doesn't make it a non-sequitur. Besides, I've explained this multiple times now, and I do so again below... and you give another non-response.\n \n \nNope. Do you have the snarky, sneering, sarcastic, demeaning schoolteacher complex? If you talk to kids the way you talk to people on this board, you should be fired, IMHO.\n\n I don't talk to my students like I have to talk to you; most of them grasp basic logic and don't insist that their LGD is a more reliable source than a degreed scientist with actual support.\n \n \nYou never \"finally got [me] to explain\" anything. I told you right from the jump that I was NOT referring to thermodynamic entropy.\n\n You repeatedly referred to statistical/logical entropy, which is directly related to thermodynamic entropy. Turns out you meant your own fantasy version of \"logical\" \"entropy\"... which is neither entropic nor logical.\n \n \nYou never \"point out\" anything. You simply make assertions that have no foundation or validity. And where does this, \"rationale you have for believing that it cannot decrease\", come from?!? Mind telling the world what the heck you think you're talking about?\n\n You claim that complexity cannot increase without an outside force (either intelligence or vitality). You justify this by defining complexity with your Looney Tunes version of \"logical entropy.\" But this version of entropy is not subject to the second law of thermodynamics, by your own admission that you're not talking about thermodynamics (or the related actual statistical entropy). Therefore there is no basis for the claim that complexity cannot increase without an outside force.\n \n \nNah. The conversation was already over. As always, you didn't realise that.\n\n Doesn't look like it's over to me. Here we are discussing the same thing...", 
   {}, 
   250262, 
   null, 
   1170910620.0
  ], 
  [
   250275, 
   null, 
   "wascallywabbit", 
   "**\n Quote:\n Originally Posted by wascallywabbit \n **\n You say \"liken to\", I say \"equates\". Enjoy playing mindless word games, don't you? \n \n I would imagine that you do, especially if you want to give your argument an extra boost. Try making your previous point using the words \"liken to.\"[/quote]\n \n **\n What point? There was no point save lyte's, who claimed that I \"likened\" \"adaptedness\" to \"negentropy\". I did not. End of story.\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n **\n \"Real entropy\". Hmm. Who went on and on about the \"no true scotsman\" fallacy. Sorry, chumly, but you don't get to say what is 'real' entropy' and what is 'false' entropy. \n \n But, as has been made clear (or so we thought) to you already, entropy can increase unless it is defined in the same way as the 2lot states it.\n\n \n **\n More nonsense. I never claimed that entropy, by any definition, cannot increase. Where are you getting this junk?!? Here is the 'entropy' definition I supplied from answers.com.\n en\u00b7tro\u00b7py (&#277;n'tr&#601;-p&#275;) \n n., pl. -pies.\n (Symbol S) For a closed thermodynamic system, a quantitative measure of the amount of thermal energy not available to do work.\n A measure of the disorder or randomness in a closed system.\n A measure of the loss of information in a transmitted message.\n The tendency for all matter and energy in the universe to evolve toward a state of inert uniformity.\n Inevitable and steady deterioration of a system or society.\n You see anything there to suggest that I don't believe that entropy cannot increase. Just the opposite, I'd say. So what are you two blathering on about?\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n **\n You never \"point out\" anything. You simply make assertions that have no foundation or validity. And where does this, \"rationale you have for believing that it cannot decrease\", come from?!? Mind telling the world what the heck you think you're talking about? \n \n There is no reason why \"information\" cannot randomly increase.\n\n \n **\n Yes, there is. If you knew the first thing about information, communication, and semiotics, you'd know that.\n \n \n\n The only accurate statement that \"entropy cannot decrease\" is known as the Second Law of Thermodynamics.No others have been tested or are in any way supported by experimentation, and you can't (logically) claim otherwise.\n \n\n \n **\n Ridiculous. Entropy decreases in open systems all the time, because much of the entropy generated in the system is expelled from it.\n WRT entropy in information-based, biosemiotic organismic and AI systems, see this and try to understand something for a change--\n \n \"entropy\n Disorder or randomness. In data compression, it is a measure of the amount of non-redundant and non-compressible data in an object (the amount that is not similar). In encryption, it is the amount of disorder or randomness that is added. In software, it is the disorder and jumble of its logic, which occurs after the program has been modified over and over. \" [answers.com]\n \n In genomes it is the number and extent of semiotic sign distortions, and subsequent loss of information/meaning, caused by random genetic mutations.", 
   {}, 
   250269, 
   null, 
   1170911400.0
  ], 
  [
   250296, 
   null, 
   "wascallywabbit", 
   "Liken to means to show as similar -- to compare -- not show as identical.\n\n \n **\n Just can't admit your splitting hairs, can you? IAC, \"liken to\" or \"equate\", the actual point was that you accused me of something I did not do. You claimed that I made a direct conflation of two separate concepts--'adaptedness' and 'negentropy'. I did not. But rather than admit the truth, you try to cover up your lie with semantic piffle.\n \n \n \n\n I'm equally qualified to point out that your brand of \"entropy\" isn't governed by the second law of thermodynamics. \n\n \n **\n Sez u. Funny, but your word and your self-styled qualifications aren't going to float that boat. The point is that in non-physical informational contexts, entropy applies,as always,-- but thermodynamics (Physics that deals with the relationships and conversions between heat and other forms of energy--answers.com), does not. The brain may heat up, but ideas don't. Your problem is your assumption that the matter in the brain is the same thing as the mind and the thoughts, emotions, etc., that it contains. Which, as pointed out to you before, is the same as thinking that the information in a newspaper is nothing more than the paper and ink used to transport the information from A to B, or even just the symbols that represent the information/meaning in a semiotic code. That kind of 19th century thought is over and done with in biology, but you'll never give up on it.\n \n \n\n Your inability to comprehend it doesn't make it a non-sequitur.\n\n \n **\n Nope, it does that all by itself, just by being what it is--a ridiculous non sequitur, by definition.\n \n \n\n I don't talk to my students like I have to talk to you; \n\n \n **\n I don't believe you for a minute. So long as the kids don't disagree with you insistently, or mount any kind of resistance to your authority, you probably keep your tongue under control. But I'll bet that any kid who doesn't kow-tow to your self-bestowed superiority gets the full benefit of your sneering sarcasm and snide insinuations.\n \n \n\n most of them grasp basic logic and don't insist that their LGD is a more reliable source than a degreed scientist with actual support.\n\n \n **\n Yeah, I'll bet you never hear a word back from any of them.\n \n \n\n You repeatedly referred to statistical/logical entropy, which is directly related to thermodynamic entropy.\n\n \n **\n Where and when did I ever, let alone repeatedly, refer to \"statistical/logical entropy\"? I referred to 'cognitive' entropy{Brig Klyce}, 'information' entropy {Shannon}, and 'semiotic' entropy{me}. When first defining 'entropy' I showed a dozen different kinds of entropy as examples, but I don't remember any of them being \"statistical/logical\" entropy.\n \n \n \n\n You claim that complexity cannot increase without an outside force (either intelligence or vitality).\n\n \n **\n Yes, complexity. Is that what you confused for 'entropy'?\n \n \n \n\n You justify this by defining complexity with your Looney Tunes version of \"logical entropy.\" \n\n \n **\n Please quote that back to me. I have no idea what you are trying to say, let alone what statement of mine you imagine you are talking about.\n \n I don't remember defining 'complexity', but speak in terms of 'complex' systems. WRT to complex systems--\n \n \"Various informal descriptions of complex systems have been put forward, and these may give some insight into their properties. A special edition of Science about complex systems Science Vol. 284. No. 5411 (1999). highlighted several of these:\n \n A complex system is a highly structured system, which shows structure with variations (Goldenfeld and Kadanoff) \n A complex system is one whose evolution is very sensitive to initial conditions or to small perturbations, one in which the number of independent interacting components is large, or one in which there are multiple pathways by which the system can evolve (Whitesides and Ismagilov) \n A complex system is one that by design or function or both is difficult to understand and verify (Weng, Bhalla and Iyengar) \n A complex system is one in which there are multiple interactions between many different components (D. Rind) \n Complex systems are systems in process that constantly evolve and unfold over time (W. Brian Arthur). \" [answers.com]\n \n WRT complex adaptive systems--[answers.com]\n \"A Complex Adaptive System (CAS) is a dynamic network of many agents (which may represent cells, species, individuals, firms, nations) acting in parallel, constantly acting and reacting to what the other agents are doing.\" \n \n \n\n But this version of entropy is not subject to the second law of thermodynamics, by your own admission that you're not talking about thermodynamics (or the related actual statistical entropy). Therefore there is no basis for the claim that complexity cannot increase without an outside force.\n\n \n **\n There's that nasty old non sequitur again.", 
   {}, 
   250272, 
   null, 
   1170918720.0
  ], 
  [
   250298, 
   null, 
   "wascallywabbit", 
   "**\n Excerpt--\n \n \"Here I shall content myself to point out that basically when biologists and physicists talk about information, they talk about different kinds of things. While information as understood by physicists has no connection to values, relevance or purpose, biologist think about information in a much more everyday language sense, and in fact biological information always serves a purpose in the system, if nothing else it at least serves to promote survival. The point is that biological information is inseparable from its context, it has to be interpreted in order to work. For example, if we discuss genetic information it should be noted, that contrary to the general image raised in textbooks there is no simple relation between the DNA coded messages and the construction of the organism, whether single celled or multi-cellular (Hoffmeyer 1995c). What is described in the DNA-text mostly concerns the amino acid sequence of the backbones of proteins and even before these backbones are actually assembled, so-called RNA-editing processes may well have introduced a context dependent element in the process (Rocha, 1995). Furthermore, how the amino acid backbones are actually folded into three-dimensional protein molecules is not itself directly specified. Neither is it fully specified how the virgin proteins should be put into the right place in the nearly unbelievably complex architecture of the cell, or how and when, in multi-cellular organisms, cells divide, differentiate or migrate in the embryonic tissue. As Harvard geneticist Richard Lewontin once said: \"First, DNA is not self-reproducing, second, it makes nothing and third, organisms are not determined by it\" (Lewontin, 1992). A more extended criticism of the DNA-centred view of biological information has been advanced by the adherents of 'developmental systems theory' (Oyama 1985, 1995; Johnston and Gottlieb 1990; Griffiths and Gray 1994).\"\n \n at--\n http://www.gypsymoth.ento.vt.edu/~sharov/biosem/hoffmeyr.html", 
   {
    "unicode_changes_made": true
   }, 
   250296, 
   null, 
   1170918840.0
  ], 
  [
   250303, 
   null, 
   "electrolyte", 
   "You claimed that I made a direct conflation of two separate concepts--'adaptedness' and 'negentropy'.\n\n Please learn to read. I said that you compared the two: you said that adaptedness cannot spontaneously increase just as \"negentropy\" cannot spontaneously increase (i.e. entropy cannot spontaneously decrease).\n \n \nThe point is that in non-physical informational contexts, entropy applies,as always,-- but thermodynamics (Physics that deals with the relationships and conversions between heat and other forms of energy--answers.com), does not.\n\n Right, but only because you're using some cockamamie LGD concept of \"entropy,\" certainly not a thermodynamic one, but not even one of statistics. If I can't use my existing understanding of the universe to contemplate your ideas, then you need to explain what words like \"information\" and \"adaptedness\" and \"complexity\" mean in this context. You've provided no coherent system of meanings such than any of your conclusions follow.\n \n \nI don't believe you for a minute.\n\n You never do, but since when do your beliefs have anything to do with reality?\n \n \nWhere and when did I ever, let alone repeatedly, refer to \"statistical/logical entropy\"?\n\n Statistical entropy is what I thought you were talking about when you started throwing out terms like \"complex\" and \"information.\" Your link to Morowitz supported this, and you said,\n And this leads to Claude Shannon's concept of informational entropy, or as Klyce calls it, 'logical entropy', which, IMHO, is the only one applicable to biosystems.\nNow you're saying you haven't talked about logical entropy... How silly of me think that you knew what you were talking about. Not only do we have the revolving door arguments, we have revolving doors within the arguments. First it's logical entropy, then it's anything besides logical entropy...\n \n \nWhen first defining 'entropy' I showed a dozen different kinds of entropy as examples, but I don't remember any of them being \"statistical/logical\" entropy.\n\n You mean, you copied and pasted a big list from wikipedia, where you went in an attempt to quickly educate yourself about something with which you hadn't the slight familiarity. Yes, I remember, and it's quite clear that you still don't know what you're talking about.\n \n \nYes, complexity. Is that what you confused for 'entropy'?\n\n \"Confused\"? You're the one who provided an entire page of \"definitions\" for \"complex system,\" one of which stated that there is no real definition. As I said a long, long time ago: you need to define your terms, else you're just blowing smoke.", 
   {}, 
   250296, 
   null, 
   1170923520.0
  ], 
  [
   250318, 
   null, 
   "wascallywabbit", 
   "Please learn to read. I said that you compared the two: you said that adaptedness cannot spontaneously increase just as \"negentropy\" cannot spontaneously increase (i.e. entropy cannot spontaneously decrease).\n\n \n **\n Quote my statement to that effect. And are you claiming that \"entropy can[] spontaneously decrease\". What do you mean by \"spontaneously\", I wonder?\n \n \n\n Right, but only because you're using some cockamamie LGD concept of \"entropy,\" certainly not a thermodynamic one, but not even one of statistics. If I can't use my existing understanding of the universe to contemplate your ideas, then you need to explain what words like \"information\" and \"adaptedness\" and \"complexity\" mean in this context. You've provided no coherent system of meanings such than any of your conclusions follow.\n\n \n **\n That's a lie. Anyone following my posts knows that I provide clear definitions for my terms from reputable reference material. But you don't like that approach since it goes against the 'special pleading' of your distorted self-serving semantics. So then you use the schoolboy sophistry of disparaging my legitimate semantics with allusions to \"Little Golden Dictionaries\". Petty mockery is about the cleanest debating technique you have. The others really suck.\n \n \n\n You never do, but since when do your beliefs have anything to do with reality?\n\n \n **\n Yada yada yada.\n \n \n\n Statistical entropy is what I thought you were talking about when you started throwing out terms like \"complex\" and \"information.\" Your link to Morowitz supported this, and you said,\n\n \n **\n My reference to \"logical\" entropy was from the Brig Klyce paper I linked.\n http://www.panspermia.com/seconlaw.htm\n It was in this paper that Boltzman's notion of thermodynamic entropy came up, (referred to by you as, 'statistical entropy'). Only 'logical' entropy had anything to do with my understanding of entropy as it applies to the complex, adaptive, autopoietic biosytems that constitute living organisms, and Klyce makes clear that 'logical' entropy is NOT 'thermodynamic' entropy. So how you managed to conflate thermodynamic \"statistical\" entropy to non-thermodynamic 'logical' entropy as 'statistical/logical' entropy I do not know.\n \n In the end there are two principal ways of looking at entropy, with about a dozen different sub-headings for thermodynamic (physical) entropy, and 3-4 sub-headings for 'logical' (psychical) entropy, so it's pretty clear to me that the concept of entropy is unclear to everybody. In which case I feel free to examine it afresh wrt to biological systems. I want to explore my own concept of \"semiotic\", or better yet, \"biosemiotic\" entropy. If you want to continue to yammer on about your steam engine notion of entropy, go ahead, but that got old pages ago.", 
   {}, 
   250303, 
   null, 
   1170948300.0
  ], 
  [
   250386, 
   null, 
   "electrolyte", 
   "Quote my statement to that effect.\n\n I'd rather not plod through all your rubbish again; let's just cut to the chase: Are you now denying that adaptedness cannot increase without an intelligence or life force? That's certainly the message you were conveying.\n \n \nSo how you managed to conflate thermodynamic \"statistical\" entropy to non-thermodynamic 'logical' entropy as 'statistical/logical' entropy I do not know.\n\n There is a relationship; both deal with microstates and macrostates as a determining factor of entropy, unless Klyce's \"logical\" entropy is different than any discussion of logical entropy that I've ever seen before.\n \n \nIn the end there are two principal ways of looking at entropy, with about a dozen different sub-headings for thermodynamic (physical) entropy, and 3-4 sub-headings for 'logical' (psychical) entropy, so it's pretty clear to me that the concept of entropy is unclear to everybody.\n\n Oh, look; wabbit has determined that \"logical\" entropy is \"psychical.\" In what way can this be derived or justified?\n I also find it comical that you can say, \"Anyone following my posts knows that I provide clear definitions for my terms from reputable reference material,\" [bold added] and then turn around and say the above, which includes \"so it's pretty clear to me that the concept of entropy is unclear to everybody.\" [bold added] \n Clear definitions that are unclear to everybody, huh? Do us a favor and restate your definitions for \"entropy,\" \"complexity,\" \"information,\" and \"adaptedness.\" This means picking or creating a single definition that accurately portrays the concept, not copying and pasting from answers.com or wikipedia. If you want to explore your own fairy-tale version of \"biosemiotic entropy,\" you'll have to establish some connection with reality. I'm not holding my breath.", 
   {}, 
   250318, 
   null, 
   1170996420.0
  ], 
  [
   250395, 
   null, 
   "wascallywabbit", 
   "I'd rather not plod through all your rubbish again;\n\n \n **\n If you are not going to read what I write, do not post responses to what you imagine I wrote.\n \n \n\n let's just cut to the chase: Are you now denying that adaptedness cannot increase without an intelligence or life force? That's certainly the message you were conveying.\n\n \n **\n No, I am not now, nor ever have, (in your contorted prose), \"den[ied]that adaptedness cannot increase without an intelligence or life force\". That is, I continue to insist that \"adaptedness\" entails the use of Vitality by organisms.\n \n \n\n There is a relationship; both deal with microstates and macrostates as a determining factor of entropy,\n\n \n **\n And just what is that supposed to mean?\n \n \n\n unless Klyce's \"logical\" entropy is different than any discussion of logical entropy that I've ever seen before.\n\n \n **\n You should make the effort to read it, then, shouldn't you?\n \n \n\n Oh, look; wabbit has determined that \"logical\" entropy is \"psychical.\" In what way can this be derived or justified?\n\n \n **\n Are you claiming that thought, emotion, logic, communication, understanding and meaning, etc. etc., are not psychical, but rather are material, corporeal, and substantive, i.e., mechanical and physical? No surprise to me if you are, but some lurkers may be a bit taken aback by your admission.\n \n \n \n\n I also find it comical that you can say, \"Anyone following my posts knows that I provide clear definitions for my terms from reputable reference material,\" [bold added] and then turn around and say the above, which includes \"so it's pretty clear to me that the concept of entropy is unclear to everybody.\" [bold added] \n Clear definitions that are unclear to everybody, huh? \n\n \n **\n You do so love feeding your jones for sophistry, don't you?! Pathetic. I looked up established definitions for 'entropy' in reputable references. I found that the word 'entropy' had been defined in many ways since its invention in the 19th century in order to account for thermodynamic phenomena. Over time it had been used in different, particular ways for different, specified phenomena. Then I posted Brig Klyes paper because it clearly outlined the semantic difficulties. \n But all along you insisted that the original thermodynamic sense of entropy was the only 'real' sense. Nothing succeeded in changing your mind. Since your stubborness and close-mindedness are insurmountable, there is no further use in trying to come to terms with you.", 
   {}, 
   250386, 
   null, 
   1171004700.0
  ], 
  [
   250400, 
   null, 
   "Abrisajac", 
   "PS: This site sucks.\n \n What is it hosted on? An ancient 386 CPU with 1MB RAM?", 
   {}, 
   250395, 
   null, 
   1171008060.0
  ], 
  [
   250425, 
   null, 
   "wascallywabbit", 
   "**\n \n The process of semiosis--\n \n \"Semiosis is the performance element involving signs. Although a human can communicate many things unintentionally, individuals usually speak or write to elicit some kind of response. Yet there is little real explanation of how semiosis produces its effects which is odd given that the word \"sign\" is in everyday use and most people would understand what it means. But semiotics has not offered clear technical definitions, nor is there agreement about how signs should be classified. So what, if anything, can be said with certainty?\n \n As an insect or animal, human or otherwise, moves through its environment (sometimes termed the Umwelt), all the senses collect data which are made available to the brain. However, to prevent sensory overload, only salient data will receive the full attention of the cognitive elements of the mind. This indicates that a part of the process must be controlled by a model of the real world capable of ranking data elements in terms of their significance and filtering out the data irrelevant to survival. A sign cannot function until the audience distinguishes it from the background noise. It then triggers cognitive activity to interpret the data input and so convert it into meaningful information. This would suggest that, in the semiosphere, the process of semiosis goes through the following cycle:\n \n the plant, insect or animal with the need to communicate will know what needs to be said and assess the best means of saying it; \n this information will then be encoded and relevant muscle groups will effect transmission - although to some extent intentional in the human, the actual movements of the body are autonomic, i.e. the individual is not aware of moving individual muscles, but achieves the desired result by an act of will (see H. L. A. Hart on the nature of an action); \n the audience filters ambient data and perceives the uttered code as a grouping of signs; \n the audience then interprets the signs (sometimes termed decoding) to attribute meaning. This involves matching the signs received against existing patterns and their meanings held in memory (i.e. it is learned and understood within the community). In plants, insects and animals, the results of a successful interpretation will be an observable response to the stimuli perceived. \n In biology, scout bees and ants will return home to tell the others where food is to be found, the fact of fertility must be announced to prospective mates from the same species, and the presence of danger must be passed as a warning to others in the group. Such transmission may be chemical, auditory, visual, or tactile whether singly or in combination. There is a new field of research activity termed biosemiotics, and Jesper Hoffmeyer claims that endosymbiosis, self-reference, code duality, the availability of receptors, autopoiesis, and others are the general properties of all living systems. Thomas Sebeok suggests that a similar list of properties for life may coincide with the definition of semiosis, i.e. that the test of whether something is alive, is a test to determine whether and how it communicates meaning to another of its kind.\" [bold mine-ww]\n \n **\n from--\n answers.com\n \n Any sensible questions or observations? Flamers and lusers will be ignored.", 
   {
    "unicode_changes_made": true
   }, 
   250400, 
   null, 
   1171047480.0
  ], 
  [
   250492, 
   null, 
   "electrolyte", 
   "If you are not going to read what I write, do not post responses to what you imagine I wrote.\n\n I do read what you write; if you in fact gave a clear definition of all of these terms (that is, not a paste of four pages from answers.com or fifteen definitions from wikipedia), you should have no trouble replicating them here. Do it already: give me a definition for [1] entropy (however you are using it this particular minute), [2] complexity, [3] adaptedness, and [4] information.\n \n \nThat is, I continue to insist that \"adaptedness\" entails the use of Vitality by organisms.\n\n Explain your reasoning for this assertion.\n \n \nAnd just what is that supposed to mean?\n\n It was a statement that somebody with an understanding of statistical thermodynamics would comprehend. You, on the other hand, are admittedly clueless as to its meaning.\n \n \nYou should make the effort to read it, then, shouldn't you?\n\n As I said earlier, he went off the deep end about a third of the way down that page. I took a look at the rest of his site earlier, too; he -- like you -- clearly has no idea what he's talking about. Did you see the \"RAQ\" where he seems to think that evolutionary theory says that frogs and birds are \"better at surviving\" than bacteria?\n \n \nAre you claiming that thought, emotion, logic, communication, understanding and meaning, etc. etc., are not psychical, but rather are material, corporeal, and substantive, i.e., mechanical and physical?\n\n No, try reading what I said. I'm claiming that you're making an assertion -- that \"logical\" entropy is psychical -- without any support whatsoever; hell, you can't even tell us what \"logical\" entropy is. I've asked several times for definitions, and all you can do is say that you've clearly explained everything. The only thing you'll have to do to make yourself look good is submit a post containing nothing but the four terms clearly defined. Then, if I ask again, you can rub my nose in the fact that you made such a post, rather than belligerently stamp your foot and fume. (Do we need to add \"pyschical\" to the list, too?)\n \n \nYou do love feeding your jones for sophistry.\n\n So it's my fault that you contradict yourself? Oh, wait... it probably is.\n \n \nBut all along you insisted that the original thermodynamic sense of entropy was the only 'real' sense.\n\n One can make up terms all the time. Did you happen to catch my zipnats post? If you want to use the word \"entropy\" to mean something other than how real scientists use it, then you need to give a definition to that effect. Your calling some concept by a name doesn't make that name accurate, but if you can tell us exactly what tinge of rose your colored glasses are, perhaps we can follow along.", 
   {}, 
   250395, 
   null, 
   1171075920.0
  ], 
  [
   250495, 
   null, 
   "electrolyte", 
   "Any sensible questions or observations? Flamers and lusers will be ignored.\n\n I have a question: When will you stop stealing things from wikipedia without citation?\n \n Real questions:\n Earlier, you said,DNA and RNA are information codes. Codes require abstract symbology. The study of signs and symbols is called 'semiotics'.\nDNA and RNA are both concrete matter. The concrete matter is physically manipulated along with other concrete molecules to eventually produce concrete peptides that perform measurable physical functions. Why are we required to appeal to abstract symbology and \"signs\" to talk about genetics?\n \n You and Klyce both want to except \"complex\" crystal formation because the physical structure already exists on a molecular level in the seed crystal. The crystallizing molecules' behavior depends upon the structure of the molecules near it. Why is this any different than, say, DNA synthesis?\n \n Will you eventually get around to how this applies to RMNS?", 
   {}, 
   250425, 
   null, 
   1171077780.0
  ], 
  [
   250501, 
   null, 
   "wascallywabbit", 
   "\n I do read what you write; if you in fact gave a clear definition of all of these terms (that is, not a paste of four pages from answers.com or fifteen definitions from wikipedia),\n\n \n **\n Gee! Resort to hyperbole much?\n \n \n\n you should have no trouble replicating them here. Do it already: give me a definition for [1] entropy (however you are using it this particular minute), [2] complexity, [3] adaptedness, and [4] information.\n\n \n **\n I don't know who the hell you think you are, throwing out commands like a junior high gym teacher, and normally I'd ignore anyone that arrogant. Especially when it's someone like you, who I know will not come to grips intellectually with anything I say, but will simply satisfy his ego with snide remarks and condescending jibes. But you're lucky tonight, as I've been planning to self-examine my own terminology for a little while, now.\n \n Starting with 'entropy'. Our exchange showed me that there are so many varying uses for that word in the modern world that it must be that no-one really knows what it is, although everyone has an instinctive feeling that it must exist as an actual entity. That puts it in the same frame as the words, 'energy', 'inertia', 'force', 'mass' and probably others that don't occur to me right now. They are all linked in that 'energy' is seen as the 'force' required to overcome the 'inertia' of a certain 'mass'. Nobody really knows what any of those words mean in non-abstract terms. So no wonder that nobody can pin down 'entropy' either, since originally it was dependent upon those other terms wherever they are encountered in mechanical systems.\n \n Now as far as I'm concerned the old, original, mechanical definition of entropy, plus all the others that have cropped up in the past 150+ years, are fine for the study of physical systems, including the corporeal bits included in biological systems. But the physical-mechanical view of biosystems is insufficient to an understanding of them. Therefore thermodynamics and its entropy I leave to physicists, chemists, and such people as are unable to discern a qualitative difference between a rock rolling downhill and a rabbit running uphill.\n \n So what form does 'entropy' take in living biosystems? First of all, all living biosystems are open systems. They only close with death. At death they, for the first time, are 100% at the mercy of the second law of thermodynamics. Their 'biological' entropy is then 100%, although their corpse's thermodynamic entropy still has a long row to hoe. Which means that life is not thermodynamic, but infodynamic, concerned with non-corporeal, non-physical, insubstantial, psychical 'energy to entropy' relations.\n \n That is, non-mechanical 'energy to entropy' relations are about 'information'.\n But what is, \"information\". Today, after years of materialist dominance, \"information\" is conflated with \"datum\". This latter-day equivocation is most unfortunate. Information is that which imparts \"meaning\". \"Data\" are meaningless facts used to create 'meaning' by discovering the significance of 2 or more facts, as discovered in their interelation with one another. That significance is 'information', and the energy of the discovery process is not thermodynamic, but psychical, since facts, ideas, significations, etc., etc., are all non-corporeal, non-physical, mental entities. Thus to me, the key to entropy wrt life and biosystems, is the 'force' that enables to organisms create and retain meaning/information, as opposed to that (?) which creates confusion, equivocation, meaninglessness, absurdity, and disinformation. That is, what I call semiotic entropy.\n \n I'll get to 'complexity' and 'adaptedness' later.", 
   {}, 
   250492, 
   null, 
   1171084020.0
  ], 
  [
   250506, 
   null, 
   "electrolyte", 
   "Jeez Louise. I ask wabbit to post straightforward, clear definitions of these words he's been throwing out -- including his (unrestricted-by-the-real-world) meaning of entropy -- and what does he do? He posts four paragraphs babbling on about different kinds of entropy and information... and it hardly clears up anything at all.\n \n \nGee! Resort to hyperbole much?\n\n Not really. You really did post (i.e. steal from wikipedia) fifteen definitions, and -- although my maximized browser window may be smaller than some -- there's over three screen-heights of babble on \"complexity\" that you ripped from various internet sources.\n \n \nBut you're lucky tonight, as I've been planning to self-examine my own terminology for a little while, now.\n\n I can't help but suspect that this has been brought on by the fact that even you can no longer deny that you don't know what you're talking about. My suspicion seems to be supported after reading your post.\n \n \nInformation is that which imparts \"meaning\". \"Data\" are meaningless facts used to create 'meaning' by discovering the significance of 2 or more facts, as discovered in their interelation with one another. That significance is 'information'...\n\n You define information as that which reveals* meaning, which you say is the significance of two or more pieces of data. Then you call that significance \"information\"... which seems to tell us that information reveals information. Regardless of what I think you actually said, I may understand what you mean. Why can't you just cut out the superfluous middle man and define information as \"the significance (i.e. interrelatedness) of two or more facts\"?\n How does one determine whether there is significance? Are there differing levels of significance?\n How does one measure the amount of information?\n * \"Impart\" can mean different things, e.g. reveal vs. transmit/give. If I have misinterpreted you such that your intended message has been lost, please clarify.\n \n \n... and the energy of the discovery process is ... psychical, since facts, ideas, significations, etc., etc., are all non-corporeal, non-physical, mental entities.\n\n Why is the discovery the important part? Why isn't the \"information\" the important part?\n Can you justify the claim that all facts are \"mental entities\"?\n Fact: no two electrons can simultaneously possess the same quantum state. How does the electron know what quantum state other electrons are in? How do electrons know which transitions are forbidden and which are not? Are electrons conscious? \"pyschical\"? Did electrons behave differently before we \"discovered\" how they behaved? If so, how could we have \"discovered\" their current behavior? \n If \"information\" is some sort of significance to the real world, then then how could anything have made sense before living beings \"discovered\" any \"meaning\"?\n \n \nThus to me, the key to entropy wrt life and biosystems, is the 'force' that enables to organisms create and retain meaning/information, as opposed to that (?) which creates confusion, equivocation, meaninglessness, absurdity, and disinformation. That is, what I call semiotic entropy.\n\n Now there's not a wonder in the world why nobody knew what the hell you were talking about. You've defined (\"semiotic\") entropy as the opposite of \"vitality,\" the existence of which you try to justify by claiming that entropic forces would otherwise make life impossible. (If this were geometry class, you would have aced the section over circles.)\n \"Creates meaninglessness\"? \"Creates disinformation\"? (Those two are the same thing, if I've understood correctly.) Semiotic entropy reduces the interrelatedness of two facts? So given enough semiotic entropy, orbiting antibonding electrons will no longer counteract effects of orbiting bonding electrons?\n Or does \"semiotic\" entropy apply only to biosystems? If so, why?\n \n Finally, what the hell does \"semiotic entropy\" have to do with \"semiosis?\" Are you proposing that all interrelatedness based on symbology?\n \n Your position is so nonsensical that -- despite the fact that it's you we're talking about here -- I figure I've misinterpreted something, uh, significant. Please explain any misconceptions you can glean from my response. Please then proceed to answer any still applicable questions.", 
   {}, 
   250501, 
   null, 
   1171093380.0
  ], 
  [
   250523, 
   null, 
   "wascallywabbit", 
   "\n I have a question: When will you stop stealing things from wikipedia without citation?\n\n \n **\n Sometimes you get get lower than a snake's belly in your attempts to win arguments by ad hominem attacks. This is one of those times. I missed giving credit for a citation I put in quotation marks headed by 'excerpt', and you accuse me of being a thief. Not only a thief, but an habitual thief. A perpetual plagiarist.\n \n Your slanders are disgusting.\n \n IAC, I got the material from, as usual, answers.com, not wikipedia. Wikipedia is apparently the original source, to which answers.com gives credit.\n \n Bottom line, your style disgusts me just too much. I can't be bothered responding to the flames of a common asshat. We're done.", 
   {}, 
   250506, 
   null, 
   1171125480.0
  ], 
  [
   250526, 
   null, 
   "wascallywabbit", 
   "**\n \n Against the materialist objection that DNA is not a \"true\" semiotic code (aka, \"scotsman\" ;)), but simply the 'start point' of a purely linear chemical process.\n \n http://www.cosmicfingerprints.com/dnanotcode.htm", 
   {}, 
   250523, 
   null, 
   1171129500.0
  ], 
  [
   250527, 
   null, 
   "wascallywabbit", 
   "**\n \n Against the notion that random and entropic events can generate meaning/information.\n \n http://www.cosmicfingerprints.com/mutationandnoise.htm\n \n or that codes arise 'naturally' (meaning, 'mechanically') in the physical world.\n \n http://www.cosmicfingerprints.com/naturallyoccurringcode.htm", 
   {}, 
   250526, 
   null, 
   1171130040.0
  ], 
  [
   250533, 
   null, 
   "johnhanks", 
   "He is an embarrassment to the human race and has no place on a public forum.\n\n Translation: he has the nerve to know something about the things I bloviate about, and to kick my butt whenever we exchange posts.", 
   {}, 
   250523, 
   null, 
   1171134060.0
  ], 
  [
   250542, 
   null, 
   "wascallywabbit", 
   "**\n Wrong thread, john.", 
   {}, 
   250533, 
   null, 
   1171138320.0
  ], 
  [
   250569, 
   null, 
   "Liminus", 
   "OK, clearly some kind of serious re-drawing of the lines is required regarding the definition of entropy here. \n I was tempted to put this in the science section as some debate is obviously needed about this individual subject for any clarity to emerge within the arguments being put forth, but as it has such relevance to the subject at hand (also for the simple reason that those involved are less likely to be regularly checking that section) I chose to post it here. \n \n If it is felt that this post does not belong in this thread I will happily delete it and repost it wherever necessary, but I will expect responses from all those involved in the current 'entropic feud', if I may call it that.\n \n Entropy is often percieved as a nebulous, imprecise term which, according to common knowledge, can be most simply described as something along the lines of \"the tendency of a system to increase towards disorder over time\". This is an understandable, but unfortunate, misunderstanding of the 2nd law.\n \n The reason entropy is viewed as such an undefinable concept is becasue the term itself describes, in one single word, a physical process which, although well-understood as a phenomenon by those who study the field of physics, involves in any real-world example the unthinkably complex process of the continuous redistribution of the energy of any given physical system.\n \n This energy at its simplest and most direct consists of the energy of particles, and the electromagnetic energy present in any system of said particles as a result of their inherent charges and also their interactions.\n \n Additionally, once we look at any system which is 'classical' in nature (ie it involves enough particles that it exhibits no quantum phenomena as a whole, which is true of all but the most microscopic, most elementary systems) we have to talk in terms of (for example) chemical energy, kinetic energy, and even the seemingly abstract (but very real) potential energy, all of which \n contribute to the energy of a system and all of which are involved in calculating that system's entropy.\n \n The first misconception that must be emphasised, however contrary to the popular view of entropy it may be, is that there is no Law of Entropy which states that order must always decrease.  This is a simplistic, although understandable, fiction. \n \n Quickly - the first and third laws of thermodynamics:\n \n 1: Mass/energy is not created or destroyed.\n \n 3: Absolute zero cannot be acieved.\n \n Nice and simple - almost common sense once some basic physical principles are understood.\n \n However, it is the 2nd law which, as we all know, creates such confusion and argument, because it deals with the distribution of energy, a far more complex principle than those with which the 1st and 3rd laws deal. While it is beyond the scope of a single post on this forum to fully explain what the second law says, I can with utmost confidence say what the second law does not say: It does not say that order must always decrease.\n \n A precise definition of entropy (aka the 2nd law) would be \"entropy is a measure of the amount of energy in a closed system that is no longer available to effect changes in that system.\" Even this clarification is not easy to comprehend, but I will try to elaborate as concisely as possible.\n \n In a closed system (which has no external source directly adding or removing energy), energy becomes unavailable by becoming irretrievably disorganised. But, even though the total amount of energy that is irretrievably disordered will increase, this does not mean order cannot increase somewhere else in that same system. \n \n In open systems, which contain additional variables, entropy can still be measured, but the 2nd law no longer strictly applies. It is not hard to see how this applies to living, biological systems, which are all open systems by definition (they must interact with their environments in order to remain biological systems ie 'living'). To further explain what this means, consider that the 2nd law quite explicitly allows a closed system to produce order, even highly elaborate order, so long as there is a greater increase in disorder somewhere else in the system. In an open system it is actually quite straightforward for said system to produce such order.\n \n In fact, nature is chock-full of examples of systems which quite naturally (spontaneously, if you will) create local order without decreasing overall entropy. Examples would be the structures of atoms causing crystallisation, and on a smaller scale, the nature of subatomic particles effecting the sorts of molecules that can form. \n \n In fact, it is as a consequence of natural physical laws, first and foremost that such order arises naturally/spontaneously in all physical systems; it is not contrary to the 2nd law to view the ensuing increase in disorder of the system as a whole, as a consequence of the creation of said order. As long as the amount of irretrievably disordered enegry is greater than the amount of ordered energy within any given system, the 2nd law is not violated. This is totally uncontroversial and agrees 100% with observed data.\n \n Mass/energy systems by their very fundamental nature and interactions produce ordered systems, but production of order necessitates an expenditure of energy. This expenditure of energy is never 100% efficient, and as such always increases the overall amount of energy that is irretrievably disordered, even as order is produced from the remaining energy. Ordering requires an increase in entropy.\n \n I sincerely hope that what I have written is comprehensible; the 2nd law is one of the most complex laws that humanity has undertaken to understand, primarily because it not only describes our specific universe, but in fact would be equally applicable in any universe which contains bits of mass-energy that never change in quantity. \n \n I also hope that this sheds some light on the current discussion.\n \n ON EDIT: I also apologise for the total absence of links; all this information comes from various physics books that I own, and also various articles science journals lent to me by a friend who is studying physics). All this information is readily available for those who care to look, but be warned: it takes (at least for me!) several thorough, concentrated readings before you can wrap your head around these theories. I personally found the 2nd law almost as taxing as I did relativity and quantum mechanics!", 
   {}, 
   250542, 
   null, 
   1171156920.0
  ], 
  [
   250590, 
   null, 
   "electrolyte", 
   "Sometimes you get get lower than a snake's belly in your attempts to win arguments by ad hominem attacks.\n\n I'm not trying to win arguments by ad hominem attacks. I provide plenty of substantive counter to your nonsense. The fact that you do things that make us question both your understanding and your integrity is simply bonus, and I don't feel particularly giving with you.\n \n \nI missed giving credit for a citation I put in quotation marks headed by 'excerpt', and you accuse me of being a thief. Not only a thief, but an habitual thief. A perpetual plagiarist.\n\n Actually, I was referring mainly to the stuff you tend to copy and paste from wikipedia specifically, not everywhere in general. Your list of fifteen definitions of entropy were taken from there without citation. Discussion of semiotics unsourced (and apparently originated from wikipedia). I appreciate wikipedia as much as the next person, but for you to be so seemingly dependent upon it only reinforces my opinion that you don't have much of a pre-existing knowledge base regarding these topics.\n \n \nAgainst the materialist objection that DNA is not a \"true\" semiotic code (aka, \"scotsman\" ), but simply the 'start point' of a purely linear chemical process.\n\n Obviously, wabbit didn't even take a gander at the iidb thread that Marshall so proudly links. Marshall had his thesis refuted by RBH (and others) before Marshall even joined the thread. He was completely unable to defend his points. The Infidels had a field day. Marshall managed a feeble 23 posts in 23 pages (that's an average of one Marshall post for every 24 Infidel posts) on a topic he claims to be his speciality, and many of these posts were pointless bluster and repetition of already-refuted points. Codec and RBH kicked his XXX for good on page 24, and Marshall hasn't been back since November, but the thread lives on... (Notice that that's when Marshall's personal page seems to have been abandoned...)The discussion continued for more than 4 months and 300 posts. At the end, nearly all participants dropped out, having failed to topple my proof or produce any new objections that had not already been addressed. In the course of a very detailed and vigorous discussion my argument did not suffer the slightest injury.\nThis guy suffers from the same problem both supersport and wabbit do: willful ignorance of the repeated slaughter of their points. On the page after Marshall disappeared, there are still thirteen or fourteen people still playfully batting around his fuzzy little argument. There are now over 600 posts, most of which do him no favors.\n \n \nAgainst the materialist objection that DNA is not a \"true\" semiotic code (aka, \"scotsman\" ;)), but simply the 'start point' of a purely linear chemical process.\n\n \nAgainst the notion that random and entropic events can generate meaning/information.\n \n ... or that codes arise 'naturally' (meaning, 'mechanically') in the physical world.\n\n Ironically, each of these are covered in the IIDB thread. (As one might expect, the simple objections I have already raised here have been raised, defended, and -- predictably -- evaded on IIDB.) I suggest that you, wabbit, should read it all and pick up where Marshall left off. Go ahead; I'll be waiting over there for you.\n \n I possibly shouldn't, but I'll give you the benefit of the doubt that you just haven't gotten around to addressing my post about your \"information\" and \"entropy\" and aren't simply working on more evasion with essentially bare links to a nutjob site created by someone so out of touch with reality that he links to a thread in which his ideas are utterly thrashed.", 
   {}, 
   250569, 
   null, 
   1171165920.0
  ], 
  [
   250593, 
   null, 
   "electrolyte", 
   "OK, clearly some kind of serious re-drawing of the lines is required regarding the definition of entropy here.\n \n [snip rest of good, accurate, potentially educational post]\n\n You've overlooked that wabbit has created an entirely new concept and decided to deceptively call it entropy. What he is talking about as \"entropy\" has no relationship to any kind of entropy I (and probably you as well) have seen discussed anywhere before. It has become quite clear, however, that he can't define (or even describe) that type of entropy in any coherent and meaningful way.", 
   {}, 
   250569, 
   null, 
   1171166820.0
  ], 
  [
   250597, 
   null, 
   "wascallywabbit", 
   "\n Entropy is often percieved as a nebulous, imprecise term which, according to common knowledge, can be most simply described as something along the lines of \"the tendency of a system to increase towards disorder over time\". This is an understandable, but unfortunate, misunderstanding of the 2nd law.\n \n The reason entropy is viewed as such an undefinable concept is becasue the term itself describes, in one single word, a physical process which, although well-understood as a phenomenon by those who study the field of physics, involves in any real-world example the unthinkably complex process of the continuous redistribution of the energy of any given physical system.\n\n \n **\n Hi liminus;\n \n Thank-you for a sincere and informed attempt to resolve the 'entropy' issue.\n \n I think that the reason that 'entropy' is so nebulous and inchoate is because it is founded upon the nebulous and inchoate concept, \"energy\".\n \n \n\n This energy at its simplest and most direct consists of the energy of particles, and the electromagnetic energy present in any system of said particles as a result of their inherent charges and also their interactions.\n\n \n **\n IOW, you attribute the source of 'energy' to 'particles', instead of the source of 'particles' to 'energy'. The ol' 'chicken/egg controvery. In the materialist metaphysical understanding of reality, all that exists is 'bits of stuff' in motion--everything else is an illusion. Therefore all non-material, non-physical, intangible, insubstantial, incorporeal phenomena are not truly real, but only abstract inferences from the material, the epiphenomena of the 'real' phenomena. This would include all abstractions, life, and all of the psychical phenomena associated with life and living. Of course, the fact that energy, entropy, mass, form, regularity--indeed, everything but 'bits of stuff in motion', is an abstraction, tends to put a crimp in the materialist epistemology.\n \n At any rate, it explains why materialists insist upon applying thermodynamic, i.e., mechanical, notions of energy and entropy to non-material, psychical phenonemena, such as meaning, information, motivation, intent, and on and on.\n \n \n\n Additionally, once we look at any system which is 'classical' in nature (ie it involves enough particles that it exhibits no quantum phenomena as a whole, which is true of all but the most microscopic, most elementary systems) we have to talk in terms of (for example) chemical energy, kinetic energy, and even the seemingly abstract (but very real) potential energy, all of which \n contribute to the energy of a system and all of which are involved in calculating that system's entropy.\n \n The first misconception that must be emphasised, however contrary to the popular view of entropy it may be, is that there is no Law of Entropy which states that order must always decrease.  This is a simplistic, although understandable, fiction.\n\n \n \n **\n What is \"order\", as you employ that term? It seems to me that you equate it to 'regularity', but I may be misunderstanding you.\n \n \n\n Quickly - the first and third laws of thermodynamics:\n \n 1: Mass/energy is not created or destroyed.\n \n 3: Absolute zero cannot be acieved.\n \n Nice and simple - almost common sense once some basic physical principles are understood.\n \n However, it is the 2nd law which, as we all know, creates such confusion and argument, because it deals with the distribution of energy, a far more complex principle than those with which the 1st and 3rd laws deal. While it is beyond the scope of a single post on this forum to fully explain what the second law says, I can with utmost confidence say what the second law does not say: It does not say that order must always decrease.\n\n \n **\n I would guess that that would depend upon your understanding of 'order/disorder', would it not?\n \n \n\n A precise definition of entropy (aka the 2nd law) would be \"entropy is a measure of the amount of energy in a closed system that is no longer available to effect changes in that system.\"\n\n \n **\n \"Available\", to whom or what in what manner?\n \n \n\n Even this clarification is not easy to comprehend, but I will try to elaborate as concisely as possible.\n \n In a closed system (which has no external source directly adding or removing energy), energy becomes unavailable by becoming irretrievably disorganised. But, even though the total amount of energy that is irretrievably disordered will increase, this does not mean order cannot increase somewhere else in that same system. \n In open systems, which contain additional variables, entropy can still be measured, but the 2nd law no longer strictly applies. It is not hard to see how this applies to living, biological systems, which are all open systems by definition (they must interact with their environments in order to remain biological systems ie 'living'). To further explain what this means, consider that the 2nd law quite explicitly allows a closed system to produce order, even highly elaborate order, so long as there is a greater increase in disorder somewhere else in the system. In an open system it is actually quite straightforward for said system to produce such order.\n\n \n **\n Since the 2LoT does not apply to 'open' biosystems, why are we talking about it?\n \n \n\n In fact, nature is chock-full of examples of systems which quite naturally (spontaneously, if you will) create local order without decreasing overall entropy. Examples would be the structures of atoms causing crystallisation, and on a smaller scale, the nature of subatomic particles effecting the sorts of molecules that can form. \n \n In fact, it is as a consequence of natural physical laws, first and foremost that such order arises naturally/spontaneously in all physical systems; it is not contrary to the 2nd law to view the ensuing increase in disorder of the system as a whole, as a consequence of the creation of said order. As long as the amount of irretrievably disordered enegry is greater than the amount of ordered energy within any given system, the 2nd law is not violated. This is totally uncontroversial and agrees 100% with observed data.\n\n \n **\n It's also perfectly in line with the \"the tendency of a system to increase towards disorder over time\" definition of entropy. \n \n \n\n Mass/energy systems by their very fundamental nature and interactions produce ordered systems, but production of order necessitates an expenditure of energy. This expenditure of energy is never 100% efficient, and as such always increases the overall amount of energy that is irretrievably disordered, even as order is produced from the remaining energy. Ordering requires an increase in entropy.\n\n \n **\n Again, without a definition of 'ordering', it's hard to say, but IMHO, 'ordering' requires, i.e., entails, an increased use of 'energy', hence an increase in 'entropy', (aka energy used by a particular system and so no longer available to that system for re-use).\n \n Anyhoo, I think that 'entropy' is something that we all could discuss 'til the cows come home, without resolution. I think that in evolution we need to concentrate on a meaning for 'entropy' and 'energy' that applies specifically to biosystems, as open systems-- self-organizing, self-ordering, self-controlled, self-serving dynamic non-linear systems.\n \n Thanks for your input. Look forward to your reply.", 
   {}, 
   250569, 
   null, 
   1171167840.0
  ], 
  [
   250603, 
   null, 
   "Liminus", 
   "**\n Hi liminus;\n \n Thank-you for a sincere and informed attempt to resolve the 'entropy' issue.\n \n I think that the reason that 'entropy' is so nebulous and inchoate is because it is founded upon the nebulous and inchoate concept, \"energy\".\n \n \n \n **\n IOW, you attribute the source of 'energy' to 'particles', instead of the source of 'particles' to 'energy'. The ol' 'chicken/egg controvery. In the materialist metaphysical understanding of reality, all that exists is 'bits of stuff' in motion--everything else is an illusion. Therefore all non-material, non-physical, intangible, insubstantial, incorporeal phenomena are not truly real, but only abstract inferences from the material, the epiphenomena of the 'real' phenomena. This would include all abstractions, life, and all of the psychical phenomena associated with life and living. Of course, the fact that energy, entropy, mass, form, regularity--indeed, everything but 'bits of stuff in motion', is an abstraction, tends to put a crimp in the materialist epistemology.\n\n \n This appears to be, IMHO, a misunderstanding of physical theory. There is nothing in the theory which views particles as the 'source' of energy. Particles are energy. When we consider the energy of a system, this energy is not in any way an extra quantity, seperate from that system, but is literally a description of that system's configuration in terms of the interactions of particles.\n \n I usually consider myself essentially materialist in outlook, but if materialism as a philosophical standpoint considers 'bits of stuff' (I would prefer to use the term 'matter') as separate from energy, and energy as a separate 'property' of matter, then I, and the vast majority of those who study physics, cannot be considered materialists; matter is energy is matter. There is no real distinction, either in theory or in reality.\n \n It may help if you look at the standard model of particle physics. Three of the four physical forces (the exception being gravity, which may not be so much a force as a by-product of the nature of spacetime) are so well-understood that not only can we model their interactions in any system, we have identified (and actually observed experimentally) the particles involved in their application. \n \n Talking about 'matter vs energy' is meaningless in modern physics; but if we are to separate the two for argument's sake, essentially the word 'matter' would refer to the configurations of quarks and electrons which form individual atoms, while 'energy' (in terms of the transfer of energy) would refer to the leptons and bosons. Your idea that energy is a \"nebulous and inchoate concept\" holds no water in modern particle physics. There is no such thing as 'pure' energy which does not involve some kind of particle. \n \n \nAt any rate, it explains why materialists insist upon applying thermodynamic, i.e., mechanical, notions of energy and entropy to non-material, psychical phenonemena, such as meaning, information, motivation, intent, and on and on.\n\n \n May I ask what, as opposed to a materialist, you consider yourself to be? As I said above, according to you (I am largely ignorant of philosophical terms, not because I have not read about them but because they are vague and individual sources often contradict one another in their definitions of said terms) I am not a materialist; if I had to pin down my worldview to a single term I would desribe myself as a 'physicist'; one who accepts the evidence of physical theory.\n \n \nWhat is \"order\", as you employ that term? It seems to me that you equate it to 'regularity', but I may be misunderstanding you...\n \n ...I would guess that that would depend upon your understanding of 'order/disorder', would it not?\n\n \n 'Order' from a physical standpoint can be understood initially as the absence of, or as a precursor to, disorder. We can think about this in terms of the eventual equilibrium of any system. Imagine a box which contains a dense gas in one corner. Over time, this gas naturally spreads out to fill the entire box. Once this has happened, the system has reached equilibrium. The individual gas particles will still move about but the gas as a whole cannot subsequently occupy a smaller portion of the box (actually it can, but only at unimaginably tiny scales as a result of quantum-mechanical phenomena). Thus, the system has reached equilibrium.\n \n Once the system has reached equilibrium it is described in physical theory as having perfect disorder, or total entropy. If we run this scenario backwards in time, the smaller a portion of the box that contains gas, the more 'ordered' the sytem is. Another way to think about this: the more ways that you can redistribute the fundamental units of a system without changing that system's overall state, the more disordered that system is; there are far more possible configurations of the gas filling the entire box than there are configurations of the gas occupying any smaller portion of it. If (in an extreme scenario) the gas was highly concentrated as a near-singularity with every particle touching in any one specific part of the box, this state has only one possible configuration and would be as ordered as it is possible to be; it would have zero entropy. \n \n In terms of biological systems (I've gotta try to keep this relevant!:) )\n there are a vast number of reconfigurations of the molecules which form amino acids which would result in that configuration of molecules being unrecognisable as an amino acid; there are only a (relatively) few possible configurations which result in an identifiable amino acid. Hence amino acids and the structures they subsequently form are considered to be extremely highly ordered.\n \n \nA precise definition of entropy (aka the 2nd law) would be \"entropy is a measure of the amount of energy in a closed system that is no longer available to effect changes in that system.\"\n\n \n \n\"Available\", to whom or what in what manner?\n\n \n I believe I have covered this above, but in case further clarification is needed: Consider again my explanations of the terms 'energy' and 'order/disorder'. Also, let's go back to the gas-in-a-box scenario. When the gas is in one corner at the start, it has a large amount of potential energy, which is expended as the gas diffuses throughout the box. Once it has filled the box and reached equilibrium, the gas still has energy (it cannot be otherwise) but this energy cannot be used to reconfigure the gas in any way other than further, almost identical configurations of the gas which also fill the entire box. \n \n \nSince the 2LoT does not apply to 'open' biosystems, why are we talking about it?\n\n \n I did not say that it no longer applies, I said it no longer strictly applies, ie open systems have by their very nature a far higher degree of flexibility in terms of the amount of order that can be created. An open system is any system which interacts with another system. As such, entropy can be 'transferred' from one system to another. Back to gas-in-a-box. \n \n Imagine a hypothetical device which can manipulate the gas within the box in any way. Once this device is in use, the {gas-in-a-box + device} is single closed system (let's say the device is battery-powered, requiring no external power source) consisting of two open systems. We use this technology to confine the gas to the corner from which it originally diffused. We have thus made the gas highly ordered once again, and massively reduced its entropy. However, this necessitates some expenditure of energy on the part of the device, which can be understood literally as an increase in disorder/entropy of the device's batteries - eventually they will run out, ie be so disordered that they no longer function as batteries. This increase in entropy will always be equal (in fact more than equal due to marginal inefficiency) to the reduction of entropy of the gas. Hence one system has 'transferred' its entropy to another. \n \n \nAs long as the amount of irretrievably disordered enegry is greater than the amount of ordered energy within any given system, the 2nd law is not violated.\n\n \n \nIt's also perfectly in line with the \"the tendency of a system to increase towards disorder over time\" definition of entropy. \n\n \n Yes, but this definition only applies, when considered precisely, to the closed system which is the entire universe. Any system smaller than the entire universe is, in some way, an open system. There are degrees of 'openness' or 'closedness' which allow us to consider some systems closed when they recieve such little energy from their environment that this energy's impact is negligible in terms of affecting observational data. \n \n For example the [gas-in-a-box + device} which I described as a closed system consisting of two open systems, is as a whole in fact an open system in that both systems will recieve energy from, at the smallest scale, the cosmic background radiation, and also (for example) the heat of the room in which the box and device are, etc. We can experimentally manipulate such factors to further extremes of negligibility, but we can never, obviously, truly isolate any system from the universe. I hope this explains why such an explanation of the 2nd law is flawed and does not sufficiently do it justice.\n \n \nAgain, without a definition of 'ordering', it's hard to say, but IMHO, 'ordering' requires, i.e., entails, an increased use of 'energy', hence an increase in 'entropy', (aka energy used by a particular system and so no longer available to that system for re-use).\n\n \n That is precisely what I said.\n \n \nAnyhoo, I think that 'entropy' is something that we all could discuss 'til the cows come home, without resolution. I think that in evolution we need to concentrate on a meaning for 'entropy' and 'energy' that applies specifically to biosystems, as open systems-- self-organizing, self-ordering, self-controlled, self-serving dynamic non-linear systems.\n\n \n Entropy and energy as physical phenomena do not require different meanings for biosystems than they do for any other systems. This is well-understood. A 'biosystem' is a very complex open system, and its behaviour in terms of thermodynamics, order/disorder, entropy is equally well-understood; there is no mystery as to how organisms regulate their entropy: They 'transfer' it to their environment through well-understood physical processes.\n \n I have put the word 'transfer' in inverted commas in every instance of my usage of the word because there is no literal 'transfer' of entropy as a physical phenomenon in itself; the reality is far more complex involving degrees of order vs disorder, or 'redistribution of energy' as explained above, but in an open system entropy can, and does, decrease while it increases in another interacting open system.", 
   {}, 
   250597, 
   null, 
   1171191420.0
  ], 
  [
   250627, 
   null, 
   "wascallywabbit", 
   "\n This appears to be, IMHO, a misunderstanding of physical theory. There is nothing in the theory which views particles as the 'source' of energy. Particles are energy. \n\n \n **\n So the greater the number of particles, (i.e., bits of stuff) contained in a barrel, the greater the amount of energy in that barrel?\n \n \n\n When we consider the energy of a system, this energy is not in any way an extra quantity, seperate from that system, but is literally a description of that system's configuration in terms of the interactions of particles.\n\n \n **\n So now you are contradicting your first statement, that \"particles are energy\".\n Now you are saying that particles themselves are not energy, but rather, it is the relationships that particles have with one another that are 'energy'. Quite a large, qualitative difference in the conceptualization of 'energy', and hence, of 'entropy'. Your first statement located 'energy' in 'substance', i.e., the Materialist ontology. Your second locates it in 'form', that is, the Idealist ontology. I'm partial to the latter, myself.\n \n \n\n I usually consider myself essentially materialist in outlook, but if materialism as a philosophical standpoint considers 'bits of stuff' (I would prefer to use the term 'matter') as separate from energy, and energy as a separate 'property' of matter, then I, and the vast majority of those who study physics, cannot be considered materialists; matter is energy is matter. There is no real distinction, either in theory or in reality.\n\n \n **\n Which is a retreat to your first statement. X amount of 'matter' = x amount of 'energy'. Either so much matter, (that is, so many particles, 'bits of stuff'), equals so much energy, or it does not. This is either true or not true. I would sugest that a ton of sand and a ton of coal, for all that they contain the same number of 'particles', do not contain the same amount of energy, and so your premise is simply wrong. That makes 'energy' a qualitative property, not a quantitative one. Energy therefore pertains to Idealism, which concerns itself with qualities, and not to Materialism, which restricts itself to quantities and their measurements.\n \n \n\n It may help if you look at the standard model of particle physics. Three of the four physical forces (the exception being gravity, which may not be so much a force as a by-product of the nature of spacetime) are so well-understood that not only can we model their interactions in any system, we have identified (and actually observed experimentally) the particles involved in their application. \n\n \n **\n Sorry, but be that as it may, what's your point?\n \n \n\n Talking about 'matter vs energy' is meaningless in modern physics; but if we are to separate the two for argument's sake, essentially the word 'matter' would refer to the configurations of quarks and electrons which form individual atoms, while 'energy' (in terms of the transfer of energy) would refer to the leptons and bosons. \n\n \n **\n So you are saying that the amount of \"energy\" in an atom equals the number of leptons and bosons in an atom, I take it? From anwers.com\n \n \"lep\u00b7ton (l&#277;p't&#335;n') \n n.\n Any of a family of elementary particles that participate in the weak interaction, including the electron, the muon, and their associated neutrinos.\"\n \n For one thing, this seems to include electrons, albeit quarks are not mentioned. \n \n \"bo\u00b7son (b&#333;'s&#335;n) \n n.\n Any of a class of particles, such as the photon, pion, or alpha particle, that have zero or integral spin and obey statistical rules permitting any number of identical particles to occupy the same quantum state.\"\n \n Now, if your statement is true, then a ton of coal must contain a great many more 'particles', as leptons and bosons, than a ton of sand, since the energy differential between the two is quite vast. Do you have evidence that that is indeed the case?\n \n \n\n Your idea that energy is a \"nebulous and inchoate concept\" holds no water in modern particle physics. There is no such thing as 'pure' energy which does not involve some kind of particle. \n\n \n **\n \"Involv[ing] some kind of particle\" is not the same thing as \"being\" some kind of particle. A ten car pileup on I-95 is not simply the fact of ten cars on a highway, but is a matter of their relationship to, and involvement with, one another. True, you cannot have, in this analogy at least, a 'pileup' without a certain number of cars, but the number is secondary to quality of their interconnectivity.\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n At any rate, it explains why materialists insist upon applying thermodynamic, i.e., mechanical, notions of energy and entropy to non-material, psychical phenonemena, such as meaning, information, motivation, intent, and on and on. \n \n \n May I ask what, as opposed to a materialist, you consider yourself to be?\n\n \n **\n I am that opposite of a Materialist, an Idealist, sub-branch Process Philosopher, including Dynamist and Vitalist. Chief influences,-- Heraklitus, Aristotle, the Stoics, Alfred North Whitehead, and Charles Saunders Pierce.\n \n \n\n As I said above, according to you (I am largely ignorant of philosophical terms, not because I have not read about them but because they are vague and individual sources often contradict one another in their definitions of said terms)\n\n \n **\n Hmmm. Reminds me of those who speak of 'energy' and 'entropy'. Funny, that.\n \n \n\n I am not a materialist; if I had to pin down my worldview to a single term I would desribe myself as a 'physicist'; one who accepts the evidence of physical theory.\n\n \n **\n Spoken like a true materialist. As a matter of fact, outside the arcane realm of professional philosophers, I have never met a materialist who would admit to being a materialist. This because in practice materialists disdain and deny all metaphysics, including their own. If pressed for a 'worldview', they immediately shelter behind euphemisms for materialist, such as 'naturalist' , or 'realist', (both terms borrowed from aethetics and the fine arts), or, as in your case, 'physicist', (a term only applied properly as a job description). But no matter. Call yourself whatever you like, it makes no difference, since the principles of ontology, epistemology, and cosmology revealed by your own words are inherently materialist.\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n What is \"order\", as you employ that term? It seems to me that you equate it to 'regularity', but I may be misunderstanding you...\n \n ...I would guess that that would depend upon your understanding of 'order/disorder', would it not? \n \n \n 'Order' from a physical standpoint can be understood initially as the absence of, or as a precursor to, disorder.\n\n \n **\n That's simply too tautologous to take us anywhere.\n \n \n\n We can think about this in terms of the eventual equilibrium of any system. Imagine a box which contains a dense gas in one corner. Over time, this gas naturally spreads out to fill the entire box. Once this has happened, the system has reached equilibrium. The individual gas particles will still move about but the gas as a whole cannot subsequently occupy a smaller portion of the box (actually it can, but only at unimaginably tiny scales as a result of quantum-mechanical phenomena). Thus, the system has reached equilibrium.\n \n Once the system has reached equilibrium it is described in physical theory as having perfect disorder, or total entropy. If we run this scenario backwards in time, the smaller a portion of the box that contains gas, the more 'ordered' the sytem is.\n\n \n **\n Just a quick interjection--this sounds like you are relating 'ordered' to 'forced', 'confined', 'defined', 'delineated', and 'controlled' and 'contained'. Am I right?\n \n \n\n Another way to think about this: the more ways that you can redistribute the fundamental units of a system without changing that system's overall state, the more disordered that system is;\n\n \n **\n Another interjection--since a 'system' is, by definition, (answers.com)\n \"sys\u00b7tem (s&#301;s't&#601;m) \n n.\n A group of interacting, interrelated, or interdependent elements forming a complex whole.\n A functionally related group of elements, especially:\n The human body regarded as a functional physiological unit.\n An organism as a whole, especially with regard to its vital processes or functions.\n A group of physiologically or anatomically complementary organs or parts: the nervous system; the skeletal system.\n A group of interacting mechanical or electrical components.\n A network of structures and channels, as for communication, travel, or distribution.\n A network of related computer software, hardware, and data transmission devices.\n An organized set of interrelated ideas or principles.\n A social, economic, or political organizational form.\n A naturally occurring group of objects or phenomena: the solar system.\n A set of objects or phenomena grouped together for classification or analysis.\n A condition of harmonious, orderly interaction.\n An organized and coordinated method; a procedure. See synonyms at method.\n The prevailing social order; the establishment. Used with the: You can't beat the system.\",\n \n how is it possible to \"redistribute the fundamental units of a system without changing that system's overall state\"? What difference does the number of ways to 'redistribute' make to its 'disorder'? A system of two parts is just as disordered after one 'redistribution' as is a system of ten parts after one 'redistribution', isn't it, if a 'system' entails the mutual interdepence of each part upon every other part. For instance, our solar system is composed of one sun and several planets. Would it take more than one 'redistribution' of any of those parts to bring about total disorder and destruction of the system, in se?\n \n \n\n there are far more possible configurations of the gas filling the entire box than there are configurations of the gas occupying any smaller portion of it. If (in an extreme scenario) the gas was highly concentrated as a near-singularity with every particle touching in any one specific part of the box, this state has only one possible configuration and would be as ordered as it is possible to be; it would have zero entropy.\n\n \n \n **\n Apart from anything else, I do not see where this talk of 'boxes', i.e., 'closed systems', is relevent to a discussion of 'open' biosystems. \n \n \n\n In terms of biological systems (I've gotta try to keep this relevant! )\n there are a vast number of reconfigurations of the molecules which form amino acids which would result in that configuration of molecules being unrecognisable as an amino acid; there are only a (relatively) few possible configurations which result in an identifiable amino acid. Hence amino acids and the structures they subsequently form are considered to be extremely highly ordered.\n\n \n **\n True, but you are still talking 'bits of stuff', not biosystems, so the relevence is still dubious. However, in terms of 'ordered', you are showing that it is a matter of form, not substance, and that it is the design, pattern, interconnectivity, interdependence, configuration, relativity _between_ the 'bits of stuff' that matters, not the actual 'bits of stuff', per se.\n \n \n\n Quote:\n Originally Posted by Liminus \n A precise definition of entropy (aka the 2nd law) would be \"entropy is a measure of the amount of energy in a closed system that is no longer available to effect changes in that system.\" \n \n \n \n Quote:\n Originally Posted by wascallywabbit \n \"Available\", to whom or what in what manner? \n \n \n I believe I have covered this above, but in case further clarification is needed: Consider again my explanations of the terms 'energy' and 'order/disorder'. Also, let's go back to the gas-in-a-box scenario. When the gas is in one corner at the start, it has a large amount of potential energy, which is expended as the gas diffuses throughout the box. Once it has filled the box and reached equilibrium, the gas still has energy (it cannot be otherwise) but this energy cannot be used to reconfigure the gas in any way other than further, almost identical configurations of the gas which also fill the entire box. \n\n \n **\n But the gas's intrinsic energy was never used to to diffuse the the gas molecules throughout the box. Something else diffused/reconfigured the gas molecules, not the gas molecules themselves. Inertia says that if you put a bunch of molecules in one corner of a box then they will stay put until acted upon by some force external to themselves. Since gas molecules don't stay put when allowed to roam, the question becomes, what force overcomes their inertia and redistributes them equitably throughout the box, with their own potential energy intact? Or is it? Generally, concentrated gasses have more actual energy, (in terms of effectiveness), than diffused gasses, even if their potential energy is the same. I think that that is why some hospital patients breathe through oxygen masks rather than the ambient atmoshere.\n \n Sorry, have to take a break.", 
   {}, 
   250603, 
   null, 
   1171224360.0
  ], 
  [
   250629, 
   null, 
   "electrolyte", 
   "I possibly shouldn't, but I'll give you the benefit of the doubt that you just haven't gotten around to addressing my post about your \"information\" and \"entropy\" and aren't simply working on more evasion with essentially bare links to a nutjob site created by someone so out of touch with reality that he links to a thread in which his ideas are utterly thrashed.\n\n As suspected, it is now apparent that I shouldn't have given wabbit the benefit of anything. He's back to his old tricks of ignoring that which he does not like. When he finally posts \"definitions\" of information and entropy, they make no sense; I expose the nonsense, and he decides to ignore me.\n \n Be that as it may, I'm getting some good chuckles at wabbit's inability to grasp physical concepts, as exposed by Liminus. Keep it up, you two!", 
   {}, 
   250590, 
   null, 
   1171225440.0
  ], 
  [
   250653, 
   null, 
   "wascallywabbit", 
   "[quote]\n \n\n Quote:\n Originally Posted by wascallywabbit \n Since the 2LoT does not apply to 'open' biosystems, why are we talking about it? \n \n \n I did not say that it no longer applies, I said it no longer strictly applies, ie open systems have by their very nature a far higher degree of flexibility in terms of the amount of order that can be created. An open system is any system which interacts with another system. As such, entropy can be 'transferred' from one system to another. Back to gas-in-a-box. \n\n \n **\n I didn't say 'why are we discussing entropy?'; I said 'why are we discussing the 2LoT?'. Forget the 2Lot and discuss entropy in open biosystems.\n \n \n\n Imagine a hypothetical device which can manipulate the gas within the box in any way. Once this device is in use, the {gas-in-a-box + device} is single closed system (let's say the device is battery-powered, requiring no external power source) consisting of two open systems. We use this technology to confine the gas to the corner from which it originally diffused. We have thus made the gas highly ordered once again, and massively reduced its entropy. However, this necessitates some expenditure of energy on the part of the device, which can be understood literally as an increase in disorder/entropy of the device's batteries - eventually they will run out, ie be so disordered that they no longer function as batteries. This increase in entropy will always be equal (in fact more than equal due to marginal inefficiency) to the reduction of entropy of the gas. Hence one system has 'transferred' its entropy to another. \n\n \n **\n Actually, the \"box\" which contains both the gas and the device and its batteries is just one closed system containing interacting parts. Thus we are back to the mechanics of the 2LoT, and irrelevent to living biosystems.\n \n \n\n Quote:\n Originally Posted by Liminus \n As long as the amount of irretrievably disordered enegry is greater than the amount of ordered energy within any given system, the 2nd law is not violated. \n \n Quote:\n Originally Posted by wascallywabbit \n It's also perfectly in line with the \"the tendency of a system to increase towards disorder over time\" definition of entropy. \n \n Yes, but this definition only applies, when considered precisely, to the closed system which is the entire universe. \n\n \n **\n Who said that this entire universe is a closed system, and on what empirical evidence is this assertion based? That fact is that you have merely stated the primary metaphysical postulate of \"Materialism\". i.e., that this physical universe constitutes the sum total of existence itself.\n \n \n\n Any system smaller than the entire universe is, in some way, an open system. There are degrees of 'openness' or 'closedness' which allow us to consider some systems closed when they recieve such little energy from their environment that this energy's impact is negligible in terms of affecting observational data. \n\n \n **\n And so we're right back to saying that 'energy' and 'entropy' are nebulous terms whose reality depends entirely and relatively upon local circumstances. I warned you that tautologies would take us nowhere.\n \n \n\n For example the [gas-in-a-box + device} which I described as a closed system consisting of two open systems, is as a whole in fact an open system in that both systems will recieve energy from, at the smallest scale, the cosmic background radiation, and also (for example) the heat of the room in which the box and device are, etc. We can experimentally manipulate such factors to further extremes of negligibility, but we can never, obviously, truly isolate any system from the universe. I hope this explains why such an explanation of the 2nd law is flawed and does not sufficiently do it justice.\n\n \n **\n well, not really. It appears to be based on a vague defense whose premise is that there are no closed systems, save for the universe entire. That's as may be, but it kind of makes the 2LoT look superfluous, even vacuous.\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n Again, without a definition of 'ordering', it's hard to say, but IMHO, 'ordering' requires, i.e., entails, an increased use of 'energy', hence an increase in 'entropy', (aka energy used by a particular system and so no longer available to that system for re-use). \n \n \n That is precisely what I said.\n\n \n **\n I'm not sure that that is precisely what you said, but if we agree, then fine.:)\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n Anyhoo, I think that 'entropy' is something that we all could discuss 'til the cows come home, without resolution. I think that in evolution we need to concentrate on a meaning for 'entropy' and 'energy' that applies specifically to biosystems, as open systems-- self-organizing, self-ordering, self-controlled, self-serving dynamic non-linear systems. \n \n \n Entropy and energy as physical phenomena do not require different meanings for biosystems than they do for any other systems. This is well-understood.\n\n \n **\n Again, no offense, but just because you believe that energy and entropy are words that each have one sole, unequivocal, universal and absolute meaning, experience tells me that you are wrong about that. And your explanations have not, to date, succeeded in being very persuasive about anything particular to living biosystems. \n \n \n \n\n A 'biosystem' is a very complex open system, and its behaviour in terms of thermodynamics, order/disorder, entropy is equally well-understood; there is no mystery as to how organisms regulate their entropy: They 'transfer' it to their environment through well-understood physical processes.\n\n \n **\n Well, yes, we all know 'what' they do. The issue is 'how' and 'why' what they do gets done. Like 'evolution', the 'what' of it is not in dispute as far as I am concerned, only the 'how' and 'why' of it.\n \n \n\n I have put the word 'transfer' in inverted commas in every instance of my usage of the word because there is no literal 'transfer' of entropy as a physical phenomenon in itself; the reality is far more complex involving degrees of order vs disorder, or 'redistribution of energy' as explained above, but in an open system entropy can, and does, decrease while it increases in another interacting open system.\n\n \n **\n Agreed, but what kind of 'energy' are we referring to, and what kind of 'entropy'. And if the change from energy to entropy is not a \"physical phenomena in itself\", then what is it?\n \n __________________", 
   {}, 
   250627, 
   null, 
   1171234500.0
  ], 
  [
   250680, 
   null, 
   "Liminus", 
   "\n So the greater the number of particles, (i.e., bits of stuff) contained in a barrel, the greater the amount of energy in that barrel?\n\n \n That's one way of looking at it. To restate, matter is energy is matter.\n \n \nSo now you are contradicting your first statement, that \"particles are energy\".\n Now you are saying that particles themselves are not energy, but rather, it is the relationships that particles have with one another that are 'energy'. Quite a large, qualitative difference in the conceptualization of 'energy', and hence, of 'entropy'. Your first statement located 'energy' in 'substance', i.e., the Materialist ontology. Your second locates it in 'form', that is, the Idealist ontology. I'm partial to the latter, myself.\n\n \n Maybe I didn't explain clearly enough. Particles are energy. The interactions between particles are carried out by other particles, namely photons (electromagnetic force), gluons (strong nuclear force) and the W and Z bosons (weak nuclear force). \n \n \nWhich is a retreat to your first statement. X amount of 'matter' = x amount of 'energy'. Either so much matter, (that is, so many particles, 'bits of stuff'), equals so much energy, or it does not. This is either true or not true. I would sugest that a ton of sand and a ton of coal, for all that they contain the same number of 'particles', do not contain the same amount of energy, and so your premise is simply wrong. That makes 'energy' a qualitative property, not a quantitative one. Energy therefore pertains to Idealism, which concerns itself with qualities, and not to Materialism, which restricts itself to quantities and their measurements.\n\n \n X amount of matter, or more precisley x number of particles, represents an amount of energy that is quantifiable. A ton of sand and a ton of coal do not represent the same amount of energy, because they definitely do not contain the same number of particles. Sand is mostly silicon dioxide, whereas coal is carbon. These molecules contain very different amounts of particles. \n \n \n... if your statement is true, then a ton of coal must contain a great many more 'particles', as leptons and bosons, than a ton of sand, since the energy differential between the two is quite vast. Do you have evidence that that is indeed the case?\n\n \n This seems to be a misunderstanding of some kind. Firstly, silicon dioxide is a larger molecule than carbon, constructed of more particles than carbon. I do not know what you mean by 'energy differential', but as we are talking about the fact that matter is energy is matter, the energy of any amount of matter is governed by the equation E=mc squared.\n \n \n\"Involv[ing] some kind of particle\" is not the same thing as \"being\" some kind of particle. A ten car pileup on I-95 is not simply the fact of ten cars on a highway, but is a matter of their relationship to, and involvement with, one another. True, you cannot have, in this analogy at least, a 'pileup' without a certain number of cars, but the number is secondary to quality of their interconnectivity.\n\n \n Again I have not explained clearly enough. Forget my use of the word 'involve'. All energy is particles. All particles are energy. This is an observationally determinable fact.\n \n \n'Order' from a physical standpoint can be understood initially as the absence of, or as a precursor to, disorder.\n\n \n \nThat's simply too tautologous to take us anywhere.\n\n \n That was the first sentence of a longer explanation, and was intended as an introduction into a way of conceptualising order and disorder.\n \n \nJust a quick interjection--this sounds like you are relating 'ordered' to 'forced', 'confined', 'defined', 'delineated', and 'controlled' and 'contained'. Am I right?\n\n \n No. None of those terms are relevant to the degree of order exhibited by a system. As I have tried to explain, a system is considered to be ordered if it cannot maintain a structure which is recognisable as that system except in a (relatively) few possible configurations, the proteins which I mentioned earlier being a perfect example of this. There are vastly more configurations of amino acids which do not make proteins, than there are which do. So proteins are considered very highly ordered.\n \n \nAnother interjection--since a 'system' is, by definition...\n\n \n A system is at its most basic, anything which consists of more than one particle. An atom is a system. Even a proton is a system (a very stable one) consisting of three quarks. \n \n \nhow is it possible to \"redistribute the fundamental units of a system without changing that system's overall state\"? What difference does the number of ways to 'redistribute' make to its 'disorder'? A system of two parts is just as disordered after one 'redistribution' as is a system of ten parts after one 'redistribution', isn't it, if a 'system' entails the mutual interdepence of each part upon every other part. For instance, our solar system is composed of one sun and several planets. Would it take more than one 'redistribution' of any of those parts to bring about total disorder and destruction of the system, in se?\n\n \n The solar system is as good an example as a protein. Think about how many ways (a staggeringly huge amount) you could reconfigure the mass-energy of the solar system which would not result in a system consisting of smaller objects orbiting a large one. There are far more ways to do this than there are ways to configure that mass-energy as the system we recognise as a solar system. Hence the solar system is also very highly ordered.\n \n A (confined) cloud of gas of size x is highly disordered, as you can reconfigure it in countless ways and it would still be recognisable as a cloud of gas of size x. There are relatively fewer ways to configure its mass-energy which result in something other than a cloud of gas of size x. This is mathematically provable. I used the qualifier 'confined' because a cloud of gas in the open is relatively highly ordered, as it can (and will) expand (ie reconfigure) in an almost infinite different number of ways. \n \n \nTrue, but you are still talking 'bits of stuff', not biosystems, so the relevence is still dubious. However, in terms of 'ordered', you are showing that it is a matter of form, not substance, and that it is the design, pattern, interconnectivity, interdependence, configuration, relativity _between_ the 'bits of stuff' that matters, not the actual 'bits of stuff', per se.\n\n \n The only word you used that is really relevant to the concepts of order and disorder is 'configuration'. I believe I have fully covered this now.\n \n \nBut the gas's intrinsic energy was never used to to diffuse the the gas molecules throughout the box. Something else diffused/reconfigured the gas molecules, not the gas molecules themselves. Inertia says that if you put a bunch of molecules in one corner of a box then they will stay put until acted upon by some force external to themselves. Since gas molecules don't stay put when allowed to roam, the question becomes, what force overcomes their inertia and redistributes them equitably throughout the box, with their own potential energy intact?\n\n \n The well-understood process of diffusion, the spontaneous movement of material from an area of high concentration to that of a lower one, which basically comes about from the random movement of the gas molecules. Gas molecules do not 'stay put', they constantly move in random directions at a speed dependent on their temperature.", 
   {}, 
   250627, 
   null, 
   1171247100.0
  ], 
  [
   250686, 
   null, 
   "Liminus", 
   "I didn't say 'why are we discussing entropy?'; I said 'why are we discussing the 2LoT?'. Forget the 2Lot and discuss entropy in open biosystems.\n\n \n To suggest discussing entropy separately from the 2LoT is nonsensical: the 2LoT governs entropy.\n \n \nActually, the \"box\" which contains both the gas and the device and its batteries is just one closed system containing interacting parts.\n\n \n Yes, a single closed system consisting of two open systems.\n \n \nThus we are back to the mechanics of the 2LoT, and irrelevent to living biosystems.\n\n \n I don't follow your logic here.\n \n \nWho said that this entire universe is a closed system, and on what empirical evidence is this assertion based? That fact is that you have merely stated the primary metaphysical postulate of \"Materialism\". i.e., that this physical universe constitutes the sum total of existence itself.\n\n \n I will admit that this is an assumption, based not on any evidence that it is true, but on the absence of any evidence to the contrary. If this is materialism, then it seems I am indeed a materialist.:) \n \n \nAny system smaller than the entire universe is, in some way, an open system. There are degrees of 'openness' or 'closedness' which allow us to consider some systems closed when they recieve such little energy from their environment that this energy's impact is negligible in terms of affecting observational data.\n\n \n \nAnd so we're right back to saying that 'energy' and 'entropy' are nebulous terms whose reality depends entirely and relatively upon local circumstances.\n\n \n No we aren't. I really don't see how you inferred that from my paragraph above, which dealt with open and closed systems. I can see how you might view the terms 'open' and 'closed' as annoyingly imprecise, but this has no impact on the very solid meanings of 'energy' and 'entropy'. \n \n \nAgain, no offense, but just because you believe that energy and entropy are words that each have one sole, unequivocal, universal and absolute meaning, experience tells me that you are wrong about that. And your explanations have not, to date, succeeded in being very persuasive about anything particular to living biosystems.\n\n \n My explanations and examples have been attempt to explain to you what entropy entails concerning the production of order and disorder in a system. I have explained the characteristics necessary for a system to be considered ordered. I have explained that the 2LoT does not forbid the production of order in closed systems, and that in open systems (for example biosystems) a high degree of order can be created and maintained due to the 'transfer' of entropy. \n \n \nWell, yes, we all know 'what' they do. The issue is 'how' and 'why' what they do gets done. Like 'evolution', the 'what' of it is not in dispute as far as I am concerned, only the 'how' and 'why' of it.\n\n \n Actually we know both the 'what' and the 'how'. As for 'why', why are protons and neutrons made of quarks? Why is the speed of light in a vacuum 299,792,458 m/s? Why does mass distort space? Why does matter even exist? I know you will say this is materialism speaking, but how can you answer such questions? \n \n \nI have put the word 'transfer' in inverted commas in every instance of my usage of the word because there is no literal 'transfer' of entropy as a physical phenomenon in itself; the reality is far more complex involving degrees of order vs disorder, or 'redistribution of energy' as explained above, but in an open system entropy can, and does, decrease while it increases in another interacting open system.\n\n \n \nAgreed, but what kind of 'energy' are we referring to, and what kind of 'entropy'. And if the change from energy to entropy is not a \"physical phenomena in itself\", then what is it?\n\n \n What kind of energy? Any kind. My phrase 'redistribution of energy' is not a very good one. Entropy is best understood in terms of order vs disorder, which I have covered at length.\n \n There is no 'change' from energy to entropy. This seems to be a misunderstanding. I was just trying to pre-empt any confusion that may have arisen due to my use of the word 'transfer' with regard to entropy. I did not want it to seem like I was saying that there is actually a literal physical embodiment of entropy which is transferred from one system to another,when the reality is that entropy decreases in one place while it increases in another.\n \n __________________[/QUOTE]", 
   {}, 
   250653, 
   null, 
   1171248960.0
  ], 
  [
   250718, 
   null, 
   "wascallywabbit", 
   "\n \n That's one way of looking at it. To restate, matter is energy is matter.\n\n \n \n **\n Well, that is certainly the materialist metaphysical assertion, but I can think of no reason to accept it.\n \n \"mat\u00b7ter (m&#259;t'&#601;r) \n n.\n \n Something that occupies space and can be perceived by one or more senses; a physical body, a physical substance, or the universe as a whole.\n Physics. Something that has mass and exists as a solid, liquid, gas, or plasma.\n \n en\u00b7er\u00b7gy (&#277;n'&#601;r-j&#275;) \n n., pl. -gies.\n The capacity for work or vigorous activity; vigor; power. See synonyms at strength.\n \n Exertion of vigor or power: a project requiring a great deal of time and energy.\n Vitality and intensity of expression: a speech delivered with energy and emotion.\n \n Usable heat or power: Each year Americans consume a high percentage of the world's energy.\n A source of usable power, such as petroleum or coal.\n Physics. The capacity of a physical system to do work.\n \n answers.com\n \n Now, matter and energy are not one and the same in these definitions. Matter is spoken of as a tangible something; energy is spoken of as an ability, power, capacity,--all abstractions. How you can exist that \"matter is energy is matter.\" on grounds of anything but the metaphysical assumption that, since all that exists are particles and their motions in space, that therefore all things (such as force, energy, motive, life, intelligence, volition, inertia, emotion, imagination, work, power, ability to, capacity for, etc.etc.) are matter, (i.e., 'particles' (bits of stuff)) that fly about on their own impulses. \n \n \n\n Quote:\n Originally Posted by wascallywabbit \n So now you are contradicting your first statement, that \"particles are energy\".\n Now you are saying that particles themselves are not energy, but rather, it is the relationships that particles have with one another that are 'energy'. Quite a large, qualitative difference in the conceptualization of 'energy', and hence, of 'entropy'. Your first statement located 'energy' in 'substance', i.e., the Materialist ontology. Your second locates it in 'form', that is, the Idealist ontology. I'm partial to the latter, myself. \n \n \n Maybe I didn't explain clearly enough. Particles are energy. The interactions between particles are carried out by other particles, namely photons (electromagnetic force), gluons (strong nuclear force) and the W and Z bosons (weak nuclear force). \n\n \n **\n So now you are claiming that photons ARE electromagnetism, gluons ARE the strong nuclear force, and that bosons ARE the weak nuclear force. Sorry, but I'm not buying.\n \n \n \n\n Quote:\n Originally Posted by wascallywabbit \n Which is a retreat to your first statement. X amount of 'matter' = x amount of 'energy'. Either so much matter, (that is, so many particles, 'bits of stuff'), equals so much energy, or it does not. This is either true or not true. I would sugest that a ton of sand and a ton of coal, for all that they contain the same number of 'particles', do not contain the same amount of energy, and so your premise is simply wrong. That makes 'energy' a qualitative property, not a quantitative one. Energy therefore pertains to Idealism, which concerns itself with qualities, and not to Materialism, which restricts itself to quantities and their measurements. \n \n \n X amount of matter, or more precisley x number of particles, represents an amount of energy that is quantifiable. A ton of sand and a ton of coal do not represent the same amount of energy, because they definitely do not contain the same number of particles. Sand is mostly silicon dioxide, whereas coal is carbon. These molecules contain very different amounts of particles. \n \n \n Quote:\n Originally Posted by wascallywabbit \n ... if your statement is true, then a ton of coal must contain a great many more 'particles', as leptons and bosons, than a ton of sand, since the energy differential between the two is quite vast. Do you have evidence that that is indeed the case? \n \n \n This seems to be a misunderstanding of some kind. Firstly, silicon dioxide is a larger molecule than carbon, constructed of more particles than carbon. I do not know what you mean by 'energy differential', but as we are talking about the fact that matter is energy is matter, the energy of any amount of matter is governed by the equation E=mc squared.\n\n \n **\n Firstly, the m in mc squared, does not stand for matter. It stands for mass. Mass is is not a particle. Mass is a measurement for inertia, another 'something' that is not a particle. Some 'particles' have mass [inertia], others do not. Energy, in Einsteinian physics, equals the amount of force required to overcome the inertial resistance of a mass bearing particle in order to bring it up to speed, that velocity being the velocity of a massless quantum, i.e., a photon, squared. \n \n If E stands for energy, and c stood for an actual photon, and a photon was a quantum of electromagnetic energy, then E=mc squared would reduce to energy=energy. But a photon is not energy. It is that which mediates or conveys or carries or transports or 'has' energy.\n \n In a Dynamist view, energy is force is energy is force. And neither force nor energy is matter. Nor, for that matter, is a particle. A particle is just a very small amount of something, and in physics that something can be either matter or energy. Meaning that massless particles like photons can be indistinguishable from the energy they mediate. But that mass bearing particles, i.e., matter, eg, the 'top' quark, can be so distinguished. \n \n Spoken as a non-physicist, but that's how it was explained to me. Feel free to show where this is a distortion of current particle physics theory. None of which, to this point in this thread, has been related to the macrophysical world of biosystems.\n \n \n \n\n Quote:\n Originally Posted by wascallywabbit \n \"Involv[ing] some kind of particle\" is not the same thing as \"being\" some kind of particle. A ten car pileup on I-95 is not simply the fact of ten cars on a highway, but is a matter of their relationship to, and involvement with, one another. True, you cannot have, in this analogy at least, a 'pileup' without a certain number of cars, but the number is secondary to quality of their interconnectivity. \n \n \n Again I have not explained clearly enough. Forget my use of the word 'involve'. All energy is particles. All particles are energy. This is an observationally determinable fact.\n\n \n **\n No, it is not. But go ahead and empirically demonstrate it, since you think you can.\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n Just a quick interjection--this sounds like you are relating 'ordered' to 'forced', 'confined', 'defined', 'delineated', and 'controlled' and 'contained'. Am I right? \n \n \n No. None of those terms are relevant to the degree of order exhibited by a system. As I have tried to explain, a system is considered to be ordered if it cannot maintain a structure which is recognisable as that system except in a (relatively) few possible configurations,\n\n \n **\n What semantic difference are you making between 'structure' and 'configuration'? It sounds to me like you are saying that a system is an ordered structure which has an essential identity that can no longer exist if that structure is modified in any essential sense. Which is another tautology.\n And is vacuous.\n \n \n\n the proteins which I mentioned earlier being a perfect example of this. There are vastly more configurations of amino acids which do not make proteins, than there are which do. So proteins are considered very highly ordered.\n\n \n **\n For that matter there are nearly infinite permutations and combinations of atoms and molecules that do not result in a moo cow. So moo cows are considered highly ordered. But any permutation or combination of atoms that results in any identifiable something can be then considered as highly ordered.\n So not only moo cows, but glasses of milk, glasses of water, rain clouds, and even your breath on a frosty morning can be considered 'ordered'. How is that helpful? It is not the fact that proteins and moo cows are ordered, but rather, what makes them ordered, gives them an identity, when so many other potential configurations do not? You may say, 'chance', but I don't have to buy that.\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n Another interjection--since a 'system' is, by definition... \n \n \n A system is at its most basic, anything which consists of more than one particle. An atom is a system. Even a proton is a system (a very stable one) consisting of three quarks. \n\n \n **\n Disagree. A system needs not only two or more parts, but a certain interrelationship between those parts. Two large stumps in a garden is not a 'system'. A system is, \"A group of interacting, interrelated, or interdependent elements forming a complex whole.\" [answers.com]. In short, a system is not things, per se, but rather their relationship with each other.\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n how is it possible to \"redistribute the fundamental units of a system without changing that system's overall state\"? What difference does the number of ways to 'redistribute' make to its 'disorder'? A system of two parts is just as disordered after one 'redistribution' as is a system of ten parts after one 'redistribution', isn't it, if a 'system' entails the mutual interdepence of each part upon every other part. For instance, our solar system is composed of one sun and several planets. Would it take more than one 'redistribution' of any of those parts to bring about total disorder and destruction of the system, in se? \n \n \n The solar system is as good an example as a protein. Think about how many ways (a staggeringly huge amount) you could reconfigure the mass-energy of the solar system which would not result in a system consisting of smaller objects orbiting a large one. There are far more ways to do this than there are ways to configure that mass-energy as the system we recognise as a solar system. Hence the solar system is also very highly ordered.\n\n \n **\n True. But if it were not 'ordered', could it exist at all? And if it were ordered differently, would it still be this solar system, or some other one?\n \n \n\n A (confined) cloud of gas of size x is highly disordered, as you can reconfigure it in countless ways and it would still be recognisable as a cloud of gas of size x. There are relatively fewer ways to configure its mass-energy which result in something other than a cloud of gas of size x. This is mathematically provable. I used the qualifier 'confined' because a cloud of gas in the open is relatively highly ordered, as it can (and will) expand (ie reconfigure) in an almost infinite different number of ways. \n\n \n **\n I don't see where this is supposed to be taking us. We are talking about systems. Systems by definition are structured. Unstructured agglomerations of stuff are irrelevent to this discussion.\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n True, but you are still talking 'bits of stuff', not biosystems, so the relevence is still dubious. However, in terms of 'ordered', you are showing that it is a matter of form, not substance, and that it is the design, pattern, interconnectivity, interdependence, configuration, relativity _between_ the 'bits of stuff' that matters, not the actual 'bits of stuff', per se. \n \n \n The only word you used that is really relevant to the concepts of order and disorder is 'configuration'. I believe I have fully covered this now.\n\n \n **\n Really? What distinguishes that word from the others?\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n But the gas's intrinsic energy was never used to to diffuse the the gas molecules throughout the box. Something else diffused/reconfigured the gas molecules, not the gas molecules themselves. Inertia says that if you put a bunch of molecules in one corner of a box then they will stay put until acted upon by some force external to themselves. Since gas molecules don't stay put when allowed to roam, the question becomes, what force overcomes their inertia and redistributes them equitably throughout the box, with their own potential energy intact? \n \n \n The well-understood process of diffusion, the spontaneous movement of material from an area of high concentration to that of a lower one, which basically comes about from the random movement of the gas molecules. Gas molecules do not 'stay put', they constantly move in random directions at a speed dependent on their temperature.\n\n \n **\n \"Diffusion\" is just a label for certain effects, random effects, that is, the disordered effects of thermal dynamics. So I guess we're back to the 2LoT. Thing is, I still don't know which force drives thermodynamics.\n __________________", 
   {}, 
   250686, 
   null, 
   1171268160.0
  ], 
  [
   250722, 
   null, 
   "T.Q", 
   "So, let me get this straight-you reject the last 150 years of biology, and the last 150 years of physics then?\n \n I can see now that you have about the same level of science knowledge as most creationists. You just have a larger vocabulary.", 
   {}, 
   250718, 
   null, 
   1171285440.0
  ], 
  [
   250741, 
   null, 
   "Liminus", 
   "**\n Well, that is certainly the materialist metaphysical assertion, but I can think of no reason to accept it...\n \n ...Now, matter and energy are not one and the same in these definitions. Matter is spoken of as a tangible something; energy is spoken of as an ability, power, capacity,--all abstractions. How you can exist that \"matter is energy is matter.\" on grounds of anything but the metaphysical assumption that, since all that exists are particles and their motions in space, that therefore all things (such as force, energy, motive, life, intelligence, volition, inertia, emotion, imagination, work, power, ability to, capacity for, etc.etc.) are matter, (i.e., 'particles' (bits of stuff)) that fly about on their own impulses.\n\n \n The defenition of energy you use applies to the way we use the term as (as I have said before) a description of a system in terms of (to use examples I have already mentioned) chemical energy, kinetic energy, potential energy. However this seemingly vague energy is anything but, as it refers purely to the particles and their inherent properties (charge, spin, mass etc) which make up a system as a whole. \n \n So the term 'energy' can be used descriptively, but when we talk about 'energy' as an actual physical thing, we are talking about mass-energy, or the equivalence of matter and energy.\n \n \nSo now you are claiming that photons ARE electromagnetism, gluons ARE the strong nuclear force, and that bosons ARE the weak nuclear force. Sorry, but I'm not buying.\n\n \n You may not buy it, but that's the way it is. These particles have been observed experimentally. \n \n \nFirstly, the m in mc squared, does not stand for matter. It stands for mass. Mass is is not a particle. Mass is a measurement for inertia, another 'something' that is not a particle. Some 'particles' have mass [inertia], others do not. Energy, in Einsteinian physics, equals the amount of force required to overcome the inertial resistance of a mass bearing particle in order to bring it up to speed, that velocity being the velocity of a massless quantum, i.e., a photon, squared.\n \n If E stands for energy, and c stood for an actual photon, and a photon was a quantum of electromagnetic energy, then E=mc squared would reduce to energy=energy. But a photon is not energy. It is that which mediates or conveys or carries or transports or 'has' energy.\n\n \n I'm not sure what your point is here, but I can, I think, reply to both paragraphs' seeming misunderstandings:\n \n 1)E=mc squared refers to the energy any mass at rest has, which is simply associated with the fact that it has mass. This is what we mean by mass-energy equivalence. For a moving body there is a different equation. This is different from the 'transfer' of energy needed to overcome inertia, which is carried out by particles.\n \n 2)as opposed to mediatingconveying/carrying/transporting energy (none of which accurately describe what actually happens) a photon indeed is energy. Of course depending on what we are describing, we can talk about the photon 'transferring' energy from one system to another, but in reality the photon is literally emitted by one system and absorbed by another. This is happening all the time.\n \n \nIn a Dynamist view, energy is force is energy is force. And neither force nor energy is matter. Nor, for that matter, is a particle. A particle is just a very small amount of something, and in physics that something can be either matter or energy. Meaning that massless particles like photons can be indistinguishable from the energy they mediate. But that mass bearing particles, i.e., matter, eg, the 'top' quark, can be so distinguished.\n\n \n Well, in the physicist view, which has actually been observed experimentally, both force and energy are equivalent to matter, as are fields as well! You are right to point out the bizarre nature of particles; you may well know that a particle actually exists as a wave/particle duality (which can be described a s a wavefunction) until it interacts with something which collapses the wavefunction to a measurable particle. A light 'wave' is both a wave and a series of photons, simultaneously. Even whole atoms have been experimentally observed to behave as waves. This may be where your confusion as to the identical nature of mass and energy arises. \n \n \nNone of which, to this point in this thread, has been related to the macrophysical world of biosystems.\n\n \n So far I have been mainly caught up in trying to explain your genuine misunderstandings of how well physical theory explains what we observe in terms of mass-energy, order/disorder, and entropy, and it was for this reason that I originally made my first post in this thread.\n \n I began by explaining entropy, which led us to order/disorder and also led us to the nature of mass-energy, all of which, no offense, you seemed to have an incomplete understanding of.\n \n I have tried a couple of times to mention how this is relevant to biosystems. If I understand you correctly, you have claimed that entropy does not allow for the creation and/or subsequent elaboration of ordered structures in biosystems. I have explained that this view is based on an unfortunate misunderstanding of the 2Lot and of entropy.\n \n \nNo, it is not. But go ahead and empirically demonstrate it, since you think you can.\n\n \n 1) If the theory of mass-energy equivalence as conceived by Einstein were not the case, there would be no nuclear reactors and no nuclear weapons.\n \n 2) We have observed all manner of mass-energy transitions, and also observed all the force-particles, mainly in large particle accelerators such as CERN on the France/Switzerland border. Before the development of such accelerators, the theory of mass-energy equivalence was just a theory. Nearly all of its predicitons have been confirmed by the use of these accelerators.\n \n \nWhat semantic difference are you making between 'structure' and 'configuration'? It sounds to me like you are saying that a system is an ordered structure which has an essential identity that can no longer exist if that structure is modified in any essential sense. Which is another tautology.\n\n \n You are confusing yourself here.\n 1) A system is anything more than one particle (see below).\n 2) The configuration (or structure, or distribution, whatever) of that system is the way in which that system's mass-energy is configured (or structured, or distributed). Configuration is the most precise term to use here; I should not have used others. \n 3) A system is not by definition 'an ordered structure' (configuration).. I have covered order/disorder already and will not do so again.\n \n \nFor that matter there are nearly infinite permutations and combinations of atoms and molecules that do not result in a moo cow. So moo cows are considered highly ordered. But any permutation or combination of atoms that results in any identifiable something can be then considered as highly ordered.\n So not only moo cows, but glasses of milk, glasses of water, rain clouds, and even your breath on a frosty morning can be considered 'ordered'. How is that helpful?\n\n \n Consider the glass of milk: the glass is highly ordered. The molecules which make up the milk are each highly ordered. The milk itself is disordered.\n A rain cloud is, when considered on its own, ignoring its environment, disordered. When we factor in the larger system of which it is a part, the atmosphere, the rain cloud is considered relatively ordered. Come on, this cannot be beyond your ability to grasp!\n \n \nIt is not the fact that proteins and moo cows are ordered, but rather, what makes them ordered, gives them an identity, when so many other potential configurations do not? You may say, 'chance', but I don't have to buy that.\n\n \n Chance has nothing to do with it. I think you still do not have a complete understanding of 'order'. Part of your question was \"what gives them an identity?\" We do. We have classified proteins as being what they are. We can look at other configurations of amino acids and say \"that is not a protein\" because it does not perform any of the chemical functions of a protein. Only then can we classify proteins as being highly ordered. If we did not yet know the difference between proteins and non-protein amino acid configurations, we would be unable to say anything about these configurations in terms of order/disorder. \n \n At a smaller scale, amino acids themselves are highly ordered, relative to the configurations of the molecules of an amino acid which do not make an amino acid. At an even smaller scale, atoms are highly ordered, relative to the configurations of protons, neutrons and electrons which do not make a stable atom (eg a bunch of electrons surrounded by a ring of protons and neutrons, a configuration that would almost instantly fly apart into a bunch of free particles.)\n \n \nDisagree. A system needs not only two or more parts, but a certain interrelationship between those parts. Two large stumps in a garden is not a 'system'. A system is, \"A group of interacting, interrelated, or interdependent elements forming a complex whole.\" [answers.com]. In short, a system is not things, per se, but rather their relationship with each other.\n\n \n But there is an interrelationship between two stumps in a garden: they both exert a tiny gravitional pull on one another. A single stump is a system, in fact quite a complex one; being made of organic material, it is a system consisting of a great number of complex molecules, which themselves are systems. Everything is part of a system; it is up to humans to decide on the scale of the system they wish to study, from the whole universe down to an atom.\n \n \nTrue. But if it were not 'ordered', could it exist at all? And if it were ordered differently, would it still be this solar system, or some other one?\n\n \n You have it backwards. The 'order' of a system is not a prerequisite for that system's existence. Once any system exists, it may then become ordered or disordered, depending on what happens, internally and externally to effect changes on that system.\n Your second question seems very close to an understanding. We can reconfigure the mass-energy of the solar system by changing the position of one particle, or by changing the position of all particles, in any possible configuration. So while the number of configurations of the mass-enery of the solar system that would be indistinguishable from what we know as the solar system is staggeringly huge, the number which would not is even huger, by a very long way. Extreme examples would be all the mass-energy of the solar system configured as;\n 1) A star orbited by only rocky planets\n 2) A star orbited by only gas giant planets\n 3) A star orbited by trillions of asteroids \n 4) A binary star system \n 5) Just a star\n 6) A huge asteroid field with no star\n 7) A vast cloud of gas\n And any number of variations and gradations of these as well as others I have not thought of. \n \n \nI don't see where this is supposed to be taking us. We are talking about systems. Systems by definition are structured. Unstructured agglomerations of stuff are irrelevent to this discussion.\n\n \n What do you mean by 'structured' and 'unstructured'? How do we tell if a system is 'structured' or not? I assume you are not equating these terms with 'order' and 'disorder'. \n If you are, systems are definitely not by definition 'ordered' as I have explained. If you are not, please clarify your terms.\n \n \nReally? What distinguishes that word from the others?\n\n \n Because the design/pattern/interconnectivity/interdependence/relativity of a system are all dependent on that system's mass-energy configuration, which is the most precise term usable for talking about order/disorder and entropy.\n \n \n\"Diffusion\" is just a label for certain effects, random effects, that is, the disordered effects of thermal dynamics. So I guess we're back to the 2LoT. Thing is, I still don't know which force drives thermodynamics.\n\n \n Diffusion is definietely not \"just a label\", it is a well-understood physical process the theory of which is accurately predictive.\n \n There is no special force that drives thermodynamics; thermodynamics is a single-word term which describes the incredibly complex processes of the 'redistribution of energy over time and space' (my phrase, and as I have admitted not a very good one), the production of ordered and disordered systems, and the descriptive concept of entropy, all of which are well-understood in terms of the effects that fundamental mass-energy units have on one another due to their inherent natures, within systems of any given size, constitution and configuration.", 
   {}, 
   250718, 
   null, 
   1171298100.0
  ], 
  [
   250751, 
   null, 
   "wascallywabbit", 
   "\n To suggest discussing entropy separately from the 2LoT is nonsensical: the 2LoT governs entropy.\n\n \n **\n Wrong. Discussing thermodynamics (i.e., mechanical entropy ,as found in linear, material/corporeal, 'particle-based' systems), separately from the 2LoT is nonsensical. Discussing the non-physical, psychical entropy involved in the non-thermal dynamics of open, autopoietic, non-linear, self-organizing, self-serving, 'information-based' systems, on the basis of the 2LoT, is nonsensical.\n \n \n Quote:\n Originally Posted by wascallywabbit \n Actually, the \"box\" which contains both the gas and the device and its batteries is just one closed system containing interacting parts. \n \n \n Yes, a single closed system consisting of two open systems.[/quote]\n \n **\n Uhm, we're not going to get anywhere is we resort to regression. We have to stick to ONE system at a time, and stop referring to parts of a given system as separate systems. Sure, it is often the case that the parts of a sytem are sub-systems, but for purposes of understanding the energy/entropy transfomation in a given system, this just gets in the way by arbitrarily dividing the issue into two or more separate issues.\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n Thus we are back to the mechanics of the 2LoT, and irrelevent to living biosystems. \n \n \n I don't follow your logic here.\n\n \n **\n See above.\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n Who said that this entire universe is a closed system, and on what empirical evidence is this assertion based? That fact is that you have merely stated the primary metaphysical postulate of \"Materialism\". i.e., that this physical universe constitutes the sum total of existence itself. \n \n \n I will admit that this is an assumption, based not on any evidence that it is true, but on the absence of any evidence to the contrary. If this is materialism, then it seems I am indeed a materialist.\n\n \n **\n And realizing that is a great step forward. \n \n \n\n Quote:\n Originally Posted by Liminus \n Any system smaller than the entire universe is, in some way, an open system. There are degrees of 'openness' or 'closedness' which allow us to consider some systems closed when they recieve such little energy from their environment that this energy's impact is negligible in terms of affecting observational data. \n \n \n \n Quote:\n Originally Posted by wascallywabbit \n And so we're right back to saying that 'energy' and 'entropy' are nebulous terms whose reality depends entirely and relatively upon local circumstances. \n \n \n No we aren't. I really don't see how you inferred that from my paragraph above, which dealt with open and closed systems. I can see how you might view the terms 'open' and 'closed' as annoyingly imprecise, but this has no impact on the very solid meanings of 'energy' and 'entropy'. \n\n \n **\n Sorry, but your reasoning is altogether faulty, and blatantly so. \n \n \n\n Quote:\n Originally Posted by wascallywabbit \n Again, no offense, but just because you believe that energy and entropy are words that each have one sole, unequivocal, universal and absolute meaning, experience tells me that you are wrong about that. And your explanations have not, to date, succeeded in being very persuasive about anything particular to living biosystems. \n \n \n My explanations and examples have been attempt to explain to you what entropy entails concerning the production of order and disorder in a system.\n\n \n **\n This despite your and lyte's insistence that entropy is not a matter of order/disorder, and so any definition of entropy as a decrease in the order, or increase in the disorder, of any given closed system, is unacceptable to you both.\n \n \n\n I have explained the characteristics necessary for a system to be considered ordered.\n\n \n **\n And done so in such a vague, indefinite way that anything stable enough to be identifiable, if only momentarily, is said to be 'ordered'. Worse, that anything so 'ordered' as to possess an identity, if only for an instant, can, by that definition, be considered to be a 'system'.\n \n \n\n I have explained that the 2LoT does not forbid the production of order in closed systems,\n\n \n **\n You have only succeeded in doing that by regressing from one closed system to an internal interchange between two or more open systems. \n Sorry, but that's cheating.\n \n \n\n and that in open systems (for example biosystems) a high degree of order can be created and maintained due to the 'transfer' of entropy. \n\n \n **\n No-one has ever questioned that. The issue remains, what kind of energy, and what kind of entropy, apply to biosystems as information-based systems?\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n Well, yes, we all know 'what' they do. The issue is 'how' and 'why' what they do gets done. Like 'evolution', the 'what' of it is not in dispute as far as I am concerned, only the 'how' and 'why' of it. \n \n \n Actually we know both the 'what' and the 'how'.\n\n \n **\n You think you know the 'how' of it. I doubt that presumption.\n \n \n\n As for 'why', why are protons and neutrons made of quarks? Why is the speed of light in a vacuum 299,792,458 m/s? Why does mass distort space? Why does matter even exist? I know you will say this is materialism speaking, but how can you answer such questions? \n\n \n **\n No, I will say that that there are different kinds of 'why' questions. Basically there are empirical 'why's', and metaphysical 'why's'. Without empirical 'why's' science and knowledge would not exist. Without metaphysical 'why's' philosophy and wisdom would not exist. Oftimes the two 'why's' intersect, but together or separately, they are still the most important question there is.\n \n The 'why' question is seldom applied to brute facts, because facts, in se, possess no meaning/information. They are merely data. Instances of existence identified. Science does not go any further than to accept facts/data for whatever it is they are. That is all that knowledge requires. Such as your \"the speed of light in a vacuum [is] 299,792,458 m/s\". Or, 2+2 make four, or any number of tautologous definitions of various brute facts.\n \n But even science sometimes ask's 'why' of brute facts, such as the 2LoT, and energy/entropy exchanges, and the meaning of it all, when they ask, why does the world, or this particular bit of it, behave as it does? \n \n \n \n\n What kind of energy? Any kind. My phrase 'redistribution of energy' is not a very good one. Entropy is best understood in terms of order vs disorder, which I have covered at length.\n\n \n **\n I fully agree, but I thought you had dismissed that point of view, in alliance with lyte's froth-at-the-mouth dismissal of it.\n \n \n\n There is no 'change' from energy to entropy. This seems to be a misunderstanding. I was just trying to pre-empt any confusion that may have arisen due to my use of the word 'transfer' with regard to entropy. I did not want it to seem like I was saying that there is actually a literal physical embodiment of entropy which is transferred from one system to another,when the reality is that entropy decreases in one place while it increases in another.\n\n \n **\n If there is no 'transfer from A to B', then what is your explanation for the phenomenon?", 
   {}, 
   250722, 
   null, 
   1171302180.0
  ], 
  [
   250759, 
   null, 
   "wascallywabbit", 
   "\n The defenition of energy you use applies to the way we use the term as (as I have said before) a description of a system in terms of (to use examples I have already mentioned) chemical energy, kinetic energy, potential energy. However this seemingly vague energy is anything but, as it refers purely to the particles and their inherent properties (charge, spin, mass etc) which make up a system as a whole. \n \n So the term 'energy' can be used descriptively, but when we talk about 'energy' as an actual physical thing, we are talking about mass-energy, or the equivalence of matter and energy.\n\n \n **\n Sorry, but this isn't making any more sense to me now then it had when you asserted it earlier on. Just how is \"the equivalence of matter and energy\" a physical thing, and not a metaphysical assumption?\n \n Here is where I find an essential flaw in your premise/postulate that energy=\n massy particles. Mass is a measurement of inertia, that is, in my understanding, the resistance to any change in direction or velocity. The power to overcome this resistance and cause a change in velocity or direction is called energy. Now if a massy particle is energy, then in effect, it overcomes its own mass. It moves itself about, however it chooses to do so.\n This is the equivalent of a man so strong that he can lift himself off the floor and hold himself out at arm's length. It equates and conflates cause with effect. Effect is its own cause, and causes its own effect. This is irrational. Worse, it's just plain silly.\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n So now you are claiming that photons ARE electromagnetism, gluons ARE the strong nuclear force, and that bosons ARE the weak nuclear force. Sorry, but I'm not buying. \n \n \n You may not buy it, but that's the way it is. These particles have been observed experimentally.\n\n \n **\n Sorry, but what they DO has been observed, but what they ARE is an assumption, no more, no less, and IMHO, a false assumption derived metaphysically. Some particles have mass and are matter. Some particles have no mass and are energy. The word 'particle' is equivocal. A better word would be 'quantum', for, 'a very small quantity'. Of either mass or energy.\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n Firstly, the m in mc squared, does not stand for matter. It stands for mass. Mass is is not a particle. Mass is a measurement for inertia, another 'something' that is not a particle. Some 'particles' have mass [inertia], others do not. Energy, in Einsteinian physics, equals the amount of force required to overcome the inertial resistance of a mass bearing particle in order to bring it up to speed, that velocity being the velocity of a massless quantum, i.e., a photon, squared.\n \n If E stands for energy, and c stood for an actual photon, and a photon was a quantum of electromagnetic energy, then E=mc squared would reduce to energy=energy. But a photon is not energy. It is that which mediates or conveys or carries or transports or 'has' energy. \n \n \n I'm not sure what your point is here, but I can, I think, reply to both paragraphs' seeming misunderstandings:\n \n 1)E=mc squared refers to the energy any mass at rest has, which is simply associated with the fact that it has mass. This is what we mean by mass-energy equivalence. For a moving body there is a different equation. This is different from the 'transfer' of energy needed to overcome inertia, which is carried out by particles.\n \n 2)as opposed to mediatingconveying/carrying/transporting energy (none of which accurately describe what actually happens) a photon indeed is energy. Of course depending on what we are describing, we can talk about the photon 'transferring' energy from one system to another, but in reality the photon is literally emitted by one system and absorbed by another. This is happening all the time.\n\n \n **\n The fact that a photon does what it does in no way determines that it is what you say it is--pure energy, i.e., the ability to overcome the inertia of a mass-possessing entity, or put the other way, the ability to overcome the mass of an inertia possessing entity. But since photons are mass/inertia-free, let's say that a quantum of electro-magnetic energy/force can be called a 'photon'. I can go with that easily enough. But when you start equating quanta of mass with quanta of energy, I get the problem I just finished going over, above. You make the mistake of conflating that which is moved with that which moves it. Now, a mass in motion can transport/transfer energy, but it cannot internally, spontaneously generate any. All of the energy it carries in its present inertial styate it gets from external forces. Even a rock rolling downhill owes all of its energy to the external forces that operated on its inertia; those that dislodged it plus the force of gravity. If a mass was the same as that which moves it, energy, then a cue ball would hit another ball and either vaporize, or keep moving without moving the ball struck. Instead it remains exactly what it is. What it does is, transfer energy to the other ball, energy that overcame its inherent mass/inertia and caused it to move, until it finally transferred all that energy to other balls or to the table. At no time were the balls and the energy they carried the exact same thing.\n \n Break time.", 
   {}, 
   250751, 
   null, 
   1171305960.0
  ], 
  [
   250760, 
   null, 
   "Liminus", 
   "\n Wrong. Discussing thermodynamics (i.e., mechanical entropy ,as found in linear, material/corporeal, 'particle-based' systems), separately from the 2LoT is nonsensical. Discussing the non-physical, psychical entropy involved in the non-thermal dynamics of open, autopoietic, non-linear, self-organizing, self-serving, 'information-based' systems, on the basis of the 2LoT, is nonsensical.\n\n \n The 2LoT governs entropy. There is also no form of entropy that is not governed by the 2LoT. The systems you mention can be explained by the standard, accepted theory of entropy which is governed by the 2LoT. The way that biosystems regulate their entropy is covered by the 2LoT.\n \n \nUhm, we're not going to get anywhere is we resort to regression. We have to stick to ONE system at a time, and stop referring to parts of a given system as separate systems. Sure, it is often the case that the parts of a sytem are sub-systems, but for purposes of understanding the energy/entropy transfomation in a given system, this just gets in the way by arbitrarily dividing the issue into two or more separate issues.\n\n \n It is, in practice, more or less imposible to stick to one system at a time, as any system apart from the smallest consists of a multitude of smaller systems. It is up to humans to define the parameters of these systems for the purposes of study.\n \n \nSorry, but your reasoning is altogether faulty, and blatantly so.\n\n \n Can you explain why? \n \n [\nThis despite your and lyte's insistence that entropy is not a matter of order/disorder, and so any definition of entropy as a decrease in the order, or increase in the disorder, of any given closed system, is unacceptable to you both.\n\n \n I have, in fact, tried to explain entropy by way of describing order and disorder, as opposed to denying any relation between these terms.\n \n Entropy can be seen as a measure of disorder. One thing I said was, there is no law of entropy that states that order must always decrease. This is true.\n \n \nAnd done so in such a vague, indefinite way that anything stable enough to be identifiable, if only momentarily, is said to be 'ordered'. Worse, that anything so 'ordered' as to possess an identity, if only for an instant, can, by that definition, be considered to be a 'system'.\n\n \n My example of the protein as an ordered structure is sufficient to understand what order refers to. I have also explicitly explained that a system does not have to be ordered for it to be a system. Everything is part of a system, and that system may exhibit degrees of order or disorder, dependent on internal and external factors.\n \n \nYou have only succeeded in doing that by regressing from one closed system to an internal interchange between two or more open systems. \n Sorry, but that's cheating.\n\n \n If a closed system with no external energy source can create order, an open system logically can not only also create order, but can do so more 'easily'. This is not rocket science.\n \n \nNo-one has ever questioned that. The issue remains, what kind of energy, and what kind of entropy, apply to biosystems as information-based systems?\n\n \n The same kinds that apply to all physical systems. They may be possible to describe conceptually as 'information-based', but this does not take away the fact that they are still physical systems.\n \n \nYou think you know the 'how' of it. I doubt that presumption.\n\n \n To take proteins for example once again, we know what they do eg protein x has x function, we also know how they do it; the protein's function is a natural consequence of its molecular configuration. It cannot do anything but perform function x.\n \n \nNo, I will say that that there are different kinds of 'why' questions. Basically there are empirical 'why's', and metaphysical 'why's'. Without empirical 'why's' science and knowledge would not exist. Without metaphysical 'why's' philosophy and wisdom would not exist. Oftimes the two 'why's' intersect, but together or separately, they are still the most important question there is.\n \n The 'why' question is seldom applied to brute facts, because facts, in se, possess no meaning/information. They are merely data. Instances of existence identified. Science does not go any further than to accept facts/data for whatever it is they are. That is all that knowledge requires. Such as your \"the speed of light in a vacuum [is] 299,792,458 m/s\". Or, 2+2 make four, or any number of tautologous definitions of various brute facts.\n \n But even science sometimes ask's 'why' of brute facts, such as the 2LoT, and energy/entropy exchanges, and the meaning of it all, when they ask, why does the world, or this particular bit of it, behave as it does?\n\n \n I agree, but metaphysical 'whys' are not necessary to understand (for example) entropy in biosystems; this is explained by the 2LoT.\n \n \nIf there is no 'transfer from A to B', then what is your explanation for the phenomenon?\n\n \n There is no transfer of entropy, which was my point, made to avoid any confusion of entropy being an actual physical 'thing' Entropy is a descriptive term.\n \n There is a transfer of actual, physical energy. Creating and maintaining order requires an expenditure of energy; according to the 2LoT, this expended energy must be (after expenditure) less ordered than whatever relatively ordered structure has been created. I have already explained why this results in the overall entropy of a system increasing, even as order, even highly elaborate order is created and maintained.", 
   {}, 
   250751, 
   null, 
   1171307340.0
  ], 
  [
   250763, 
   null, 
   "Liminus", 
   "**\n Sorry, but this isn't making any more sense to me now then it had when you asserted it earlier on. Just how is \"the equivalence of matter and energy\" a physical thing, and not a metaphysical assumption?\n \n Here is where I find an essential flaw in your premise/postulate that energy=\n massy particles. Mass is a measurement of inertia, that is, in my understanding, the resistance to any change in direction or velocity. The power to overcome this resistance and cause a change in velocity or direction is called energy. Now if a massy particle is energy, then in effect, it overcomes its own mass. It moves itself about, however it chooses to do so.\n This is the equivalent of a man so strong that he can lift himself off the floor and hold himself out at arm's length. It equates and conflates cause with effect. Effect is its own cause, and causes its own effect. This is irrational. Worse, it's just plain silly.\n\n \n When we talk about mass-energy equivalence, we are talking about rest-mass energy, which refers to the energy that would be liberated if x amount of mass were entirely converted to energy. A single atom, converts to a relatively huge amount of energy. A unit of energy, conversely, has an incredibly tiny, but real mass. For example, the sun gives out roughly 4 million tons of light per second. Photons have zero mass measured in the way we normally measure it, but they have energy, which is equivalent to mass. \n \n This may sound contradictory, but we use the words 'matter' and 'energy' to describe certain recongnisable functions of mass-energy units, the reality is that matter and energy are different expressions of a single phenomenon, which is explained more satisfactorily by quantum mechanics.\n \n \nSorry, but what they DO has been observed, but what they ARE is an assumption, no more, no less, and IMHO, a false assumption derived metaphysically. Some particles have mass and are matter. Some particles have no mass and are energy. The word 'particle' is equivocal. A better word would be 'quantum', for, 'a very small quantity'. Of either mass or energy.\n\n \n The word 'particle' is just a word we use for the basic mass-energy units. It does not imply any description of what that particle is. Indeed, the use of the word 'quantum' is very much applied in modern physics, especially when talking about individual units. It is quite acceptable, but unconventional, to replace every instance of the word 'particle' with the word 'quantum' in scientific literature.\n \n \nThe fact that a photon does what it does in no way determines that it is what you say it is--pure energy, i.e., the ability to overcome the inertia of a mass-possessing entity, or put the other way, the ability to overcome the mass of an inertia possessing entity. But since photons are mass/inertia-free, let's say that a quantum of electro-magnetic energy/force can be called a 'photon'. I can go with that easily enough. But when you start equating quanta of mass with quanta of energy, I get the problem I just finished going over, above. You make the mistake of conflating that which is moved with that which moves it. Now, a mass in motion can transport/transfer energy, but it cannot internally, spontaneously generate any. All of the energy it carries in its present inertial styate it gets from external forces. Even a rock rolling downhill owes all of its energy to the external forces that operated on its inertia; those that dislodged it plus the force of gravity. If a mass was the same as that which moves it, energy, then a cue ball would hit another ball and either vaporize, or keep moving without moving the ball struck. Instead it remains exactly what it is. What it does is, transfer energy to the other ball, energy that overcame its inherent mass/inertia and caused it to move, until it finally transferred all that energy to other balls or to the table. At no time were the balls and the energy they carried the exact same thing.\n\n \n You are confusing rest-mass energy with other,descriptive forms of energy. You said \"Even a rock rolling downhill owes all of its energy to the external forces that operated on its inertia; those that dislodged it plus the force of gravity.\" \n \n This is true for the kinetic and potential energy of the rock, but these are just human-imposed descriptions of the evolution of the state of the rock, but when we talk about energy as a physical entity, we are talking about the energy which exists as mass-energy units; particles or 'quanta' if you prefer.", 
   {}, 
   250759, 
   null, 
   1171308780.0
  ], 
  [
   250829, 
   null, 
   "wascallywabbit", 
   "**\n \n At the rate you're turning out response I may never catch up, but that's OK, gives me lots of mind-fodder, and that's what I'm here for.\n \n \n\n Well, in the physicist view, which has actually been observed experimentally, both force and energy are equivalent to matter, as are fields as well!\n\n \n **\n And waves as well, I suppose. After all, if you start out with an 'a priori' metaphysical assumption that everything is matter/mass, and nothing is not matter/mass, then what other conclusion can you lead yourself to?\n \n BTW, \"equivalent\" means 'equal to' in some particular aspect. Such as, that horse is equivalent to this cow wrt weight and grass-eating capacity. It does not mean that a horse is a cow. Force and energy may equate to matter in certains respects, but that does not at all make them the same thing.\n \n Just for fun, when you say, \"matter\", what do you mean by that word! One more time, here is what I mean when I use it,-- [answers.com]\n \n \"mat\u00b7ter (m&#259;t'&#601;r) \n n.\n \n Something that occupies space and can be perceived by one or more senses; a physical body, a physical substance, or the universe as a whole.\n Physics. Something that has mass and exists as a solid, liquid, gas, or plasma. [bold mine]\n \n Obviously you must be using some very different definition of 'matter', and I'd really like to know what it is.\n \n \n\n You are right to point out the bizarre nature of particles; you may well know that a particle actually exists as a wave/particle duality (which can be described a s a wavefunction) until it interacts with something which collapses the wavefunction to a measurable particle. A light 'wave' is both a wave and a series of photons, simultaneously. Even whole atoms have been experimentally observed to behave as waves. This may be where your confusion as to the identical nature of mass and energy arises.\n\n \n **\n I do not see myself as confused, and yes, I am familiar with 'wave/particle duality', slit-experiments and whatnot. And I notice, before you were talking \"the identical nature of [particles] and energy\", so at least what I take to be your own confusion is abating somewhat. You're still trying to conflate cause with effect, however, when you claim that mass/inertia in an entity, and the force/energy needed to overcome it, are the exact same thing, and not simply equivalent to one another, as per my horse/cow example. And that is still utterly irrational. \n \n \n\n Quote:\n Originally Posted by wascallywabbit \n None of which, to this point in this thread, has been related to the macrophysical world of biosystems. \n \n \n So far I have been mainly caught up in trying to explain your genuine misunderstandings of how well physical theory explains what we observe in terms of mass-energy, order/disorder, and entropy, and it was for this reason that I originally made my first post in this thread.\n\n \n \n **\n Sadly, you have failed to show any misunderstanding on my part, even though you keep repeating the same assertions over and over, without ever actually coming to grips with my objections to them, beyond some vague appeal to the authority of 'physics', whatever that is supposed to mean.\n \n \n\n I began by explaining entropy,\n\n \n **\n No, you began by repeating everything lyte had said about the 2LoT and thermodynamic entropy. You then veered away from lyte and admitted, contra lyte, that 'order/disorder' was a valid approach to 'energy/entropy', but you still stuck to thermodynamics and the 2LoT as the one and only reality, with mechanical/physical order/disorder, structure/entropy, in existence. You then threw in random agglomerations of gas molecules as if they constituted 'systems', and from that went to trying to explain a closed system, as per the 2LoT, in terms of its parts being two or more open systems, as an attempt to justify your assertion that the 2LoT allows for an increase in order, decrease in entropy, in a closed system; which it does not, in fact, do.\n \n \n\n which led us to order/disorder and also led us to the nature of mass-energy, all of which, no offense, you seemed to have an incomplete understanding of.\n\n \n **\n Admittedly, I have have an incomplete understanding of just about everything in the universe, and expect to go to my grave not a whole heck of a lot better off than I am now. But do not label my non-acceptance of your opinions as my 'ignorance' or 'failure to understand'. No offense, but I understand what you are saying perfectly well. I simply don't accept your premises, (particularly the premise that mass and energy are the very same thing), and feel no rational compulsion to buy into them, so far. To the contrary, in fact.\n \n \n\n I have tried a couple of times to mention how this is relevant to biosystems. If I understand you correctly, you have claimed that entropy does not allow for the creation and/or subsequent elaboration of ordered structures in biosystems. \n\n \n **\n If that is your understanding of my position, then you have misunderstood me completely, and I confess that I have not the least idea where you gained that impression. It was never from anything I said.\n \n What I have said, repeatedly, is that biosystems are open systems, those that input energy and generate new information in the form of novel complex structures and processes, or simply to maintain old ones, while outputting entropy as failed concepts, random mistakes, accidents-- i.e., disinformation.\n THat is, to input Vitality to internally generate and conserve meaning and significance, while ouputting [as entropy], senselessness and meaninglessness wrt the biosystem's own identity.\n \n The difference between us is that you base your understanding of biosystems on thermodynamics, and I base mine on semiotics. Another difference between us is that you maintain that all of the energy input into an open system comes in the form of massy particles, whereas I insist that mass and energy are equivalent, (in so far as it requires so much energy to effect a given mass to given degree), but that a 'mass' and the energy it carries, and inertia and the force needed to overcome it, are not at all identical entities.\n \n \n\n I have explained that this view is based on an unfortunate misunderstanding of the 2Lot and of entropy.\n\n \n **\n Well, no, you have repeatedly made that assertion, but youy've come nowhere close to demonstrating anything other than that we disagree.\n \n \n\n 1) If the theory of mass-energy equivalence as conceived by Einstein were not the case, there would be no nuclear reactors and no nuclear weapons.\n\n \n **\n As above, 'equivalence' is NOT 'sameness'. What a thing is, is not the same as what it is equal to. Saying that my pair of aces equals your pair of aces is NOT saying that my pair of aces IS your pair of aces.\n \n And that is how equations, including the famous E=MCsquared, are meant to be interpreted.\n \n \n\n 2) We have observed all manner of mass-energy transitions, and also observed all the force-particles, mainly in large particle accelerators such as CERN on the France/Switzerland border. Before the development of such accelerators, the theory of mass-energy equivalence was just a theory. Nearly all of its predicitons have been confirmed by the use of these accelerators.\n\n \n **\n Once again, your problem is that you do not understand the meaning of the verb 'to equal' and its cognates, as opposed to the verb 'to be' and its cognates.\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n What semantic difference are you making between 'structure' and 'configuration'? It sounds to me like you are saying that a system is an ordered structure which has an essential identity that can no longer exist if that structure is modified in any essential sense. Which is another tautology. \n \n \n You are confusing yourself here.\n 1) A system is anything more than one particle (see below).\n\n \n **\n Wrong. Two plates on a table is not a system. To be a system there needs must be interaction between parts in order to act as one whole. You can have a billion 'particles', from sub-atomic quanta to macroscopic bits of salt, and have no 'system' at all.\n \n \n\n 2) The configuration (or structure, or distribution, whatever) of that system is the way in which that system's mass-energy is configured (or structured, or distributed). Configuration is the most precise term to use here; I should not have used others. \n\n \n **\n All you are saying is that configuration is configuration. Such tautologies are non-explanatory.\n \n \n\n 3) A system is not by definition 'an ordered structure' (configuration).. I have covered order/disorder already and will not do so again.\n\n \n **\n Well, I'm glad that we won't have to repeat ourselves.\n \n \n\n Consider the glass of milk: the glass is highly ordered. The molecules which make up the milk are each highly ordered. The milk itself is disordered.\n A rain cloud is, when considered on its own, ignoring its environment, disordered. When we factor in the larger system of which it is a part, the atmosphere, the rain cloud is considered relatively ordered. Come on, this cannot be beyond your ability to grasp!\n\n \n **\n What's there to grasp?!? No offense I hope, but you are not saying anything; you are just stringing words together. What's your point?!?!\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n It is not the fact that proteins and moo cows are ordered, but rather, what makes them ordered, gives them an identity, when so many other potential configurations do not? You may say, 'chance', but I don't have to buy that. \n \n \n Chance has nothing to do with it. I think you still do not have a complete understanding of 'order'.\n\n \n **\n So you say, and so therefore you will be able to tell me what does have to do with it, since 'chance' does not?\n \n \n\n Part of your question was \"what gives them an identity?\" We do. We have classified proteins as being what they are. We can look at other configurations of amino acids and say \"that is not a protein\" because it does not perform any of the chemical functions of a protein. Only then can we classify proteins as being highly ordered. If we did not yet know the difference between proteins and non-protein amino acid configurations, we would be unable to say anything about these configurations in terms of order/disorder. \n\n \n **\n Uhm, who's this 'we' you speak of? Our various particles?\n \n \n\n But there is an interrelationship between two stumps in a garden: they both exert a tiny gravitional pull on one another. A single stump is a system, in fact quite a complex one; being made of organic material, it is a system consisting of a great number of complex molecules, which themselves are systems. Everything is part of a system; it is up to humans to decide on the scale of the system they wish to study, from the whole universe down to an atom.\n\n \n **\n By saying that everything is a system you have effectively rendered the word, 'system', meaningless, and the concept absurd.\n \n \n\n You have it backwards. The 'order' of a system is not a prerequisite for that system's existence. Once any system exists, it may then become ordered or disordered, depending on what happens, internally and externally to effect changes on that system.\n\n \n **\n What can I say? To me, with apologies, this is sheer nonsense.\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n I don't see where this is supposed to be taking us. We are talking about systems. Systems by definition are structured. Unstructured agglomerations of stuff are irrelevent to this discussion. \n \n \n What do you mean by 'structured' and 'unstructured'? How do we tell if a system is 'structured' or not? I assume you are not equating these terms with 'order' and 'disorder'. \n If you are, systems are definitely not by definition 'ordered' as I have explained. If you are not, please clarify your terms.\n\n \n **\n Once again, your assertions are not explanations. By 'structured/unstructered' I certainly do mean, 'ordered/disordered', and that 'systems' are ordered/structured and that non-systems, ie., simple agglomerates, confused and jumbled heaps or raw quantities of stuff, are not. I repeat--a system is not a system unless it is composed of a number of parts that interact with each other in an orderly fashion.\n \n \n\n Because the design/pattern/interconnectivity/interdependence/relativity of a system are all dependent on that system's mass-energy configuration, which is the most precise term usable for talking about order/disorder and entropy.\n\n \n **\n They are not \"dependent on it\". They are synonymous with it, or \"equivalent\" to it. :)\n \n \n \n\n Quote:\n Originally Posted by wascallywabbit \n \"Diffusion\" is just a label for certain effects, random effects, that is, the disordered effects of thermal dynamics. So I guess we're back to the 2LoT. Thing is, I still don't know which force drives thermodynamics. \n \n \n Diffusion is definietely not \"just a label\", it is a well-understood physical process the theory of which is accurately predictive.\n\n \n **\n It is a name for an effect, but it is not an explanation for that effect. What is the force that creates that effect? Apparently thermodynamics. What force drives thermodynamics? Gravity, electro-magnetism, strong and weak nuclear? Any ideas?\n \n \n\n There is no special force that drives thermodynamics; thermodynamics is a single-word term which describes the incredibly complex processes of the 'redistribution of energy over time and space' (my phrase, and as I have admitted not a very good one), the production of ordered and disordered systems, and the descriptive concept of entropy, all of which are well-understood in terms of the effects that fundamental mass-energy units have on one another due to their inherent natures, within systems of any given size, constitution and configuration.\n\n \n **\n IOW, it's just a label.", 
   {}, 
   250763, 
   null, 
   1171327560.0
  ], 
  [
   250834, 
   null, 
   "wascallywabbit", 
   "\n The 2LoT governs entropy. There is also no form of entropy that is not governed by the 2LoT. The systems you mention can be explained by the standard, accepted theory of entropy which is governed by the 2LoT. The way that biosystems regulate their entropy is covered by the 2LoT.\n\n \n **\n Yes, I've heard you say this several times.\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n Uhm, we're not going to get anywhere is we resort to regression. We have to stick to ONE system at a time, and stop referring to parts of a given system as separate systems. Sure, it is often the case that the parts of a sytem are sub-systems, but for purposes of understanding the energy/entropy transfomation in a given system, this just gets in the way by arbitrarily dividing the issue into two or more separate issues. \n \n \n It is, in practice, more or less imposible to stick to one system at a time, as any system apart from the smallest consists of a multitude of smaller systems. It is up to humans to define the parameters of these systems for the purposes of study.\n\n \n **\n Sure it is. So when we talk, establish the parameters and stick to them.\n \n \n\n The same kinds that apply to all physical systems. They may be possible to describe conceptually as 'information-based', but this does not take away the fact that they are still physical systems.\n\n \n **\n The point is that they are not simply and only physical (mechanical) systems.\n \n \n\n Quote:\n Originally Posted by wascallywabbit \n If there is no 'transfer from A to B', then what is your explanation for the phenomenon? \n \n \n There is no transfer of entropy, which was my point, made to avoid any confusion of entropy being an actual physical 'thing' Entropy is a descriptive term.\n\n \n **\n So you are now saying that 'entropy' is an abstraction, a mere semantic label?\n That it is not a real and actual physical phenomenon?\n \n \n \n\n There is a transfer of actual, physical energy. Creating and maintaining order requires an expenditure of energy; according to the 2LoT, this expended energy must be (after expenditure) less ordered than whatever relatively ordered structure has been created. I have already explained why this results in the overall entropy of a system increasing, even as order, even highly elaborate order is created and maintained.\n\n \n **\n We already know that for open systems, like biosystems. You tried to apply it toclosed systems by refressing one closed system into two open systems. As I said at the time, that's cheating. Establish paremeters, and stick to them.\n \n I've skipped a lot of stuff because we're getting repetitive. Bound to happen, I suppose.\n __________________", 
   {}, 
   250829, 
   null, 
   1171331580.0
  ], 
  [
   250836, 
   null, 
   "wascallywabbit", 
   "When we talk about mass-energy equivalence, we are talking about rest-mass energy, which refers to the energy that would be liberated if x amount of mass were entirely converted to energy.\n\n \n **\n Interesting word, \"to convert\". Basically it means to change something into something else. Something you could not do with mass and energy, i.e.,\n 'converting ' the one into the other, if mass and energy were the same thing to begin with.\n \n \n\n A single atom, converts to a relatively huge amount of energy. A unit of energy, conversely, has an incredibly tiny, but real mass. For example, the sun gives out roughly 4 million tons of light per second. Photons have zero mass measured in the way we normally measure it, but they have energy, which is equivalent to mass. \n\n \n **\n Equivalent, yes--the same, not. Light can be affected by gravity, which equates to weight measures, but weight only tangentially relates to mass, which is a measure of inertia. There is not doubt that photons are quanta of electromagnetic energy, but they have no mass, and so their non-existent mass is not their actual energy. That the force of gravity can operate upon the force of electromagnetism is interesting, to say the least.\n \n \n\n This may sound contradictory, but we use the words 'matter' and 'energy' to describe certain recongnisable functions of mass-energy units, the reality is that matter and energy are different expressions of a single phenomenon, which is explained more satisfactorily by quantum mechanics.\n\n \n **\n Everything reduces to one thing, in the end. You say it reduces to 'mass'. I say it reduces to 'meaning'.\n \n \n\n The word 'particle' is just a word we use for the basic mass-energy units. It does not imply any description of what that particle is. Indeed, the use of the word 'quantum' is very much applied in modern physics, especially when talking about individual units. It is quite acceptable, but unconventional, to replace every instance of the word 'particle' with the word 'quantum' in scientific literature.\n\n \n **\n That's what I thought, and since 'particle' implies 'corporeal', I'll use quantum.\n \n \n\n You are confusing rest-mass energy with other,descriptive forms of energy. You said \"Even a rock rolling downhill owes all of its energy to the external forces that operated on its inertia; those that dislodged it plus the force of gravity.\" \n \n This is true for the kinetic and potential energy of the rock, but these are just human-imposed descriptions of the evolution of the state of the rock, but when we talk about energy as a physical entity, we are talking about the energy which exists as mass-energy units; particles or 'quanta' if you prefer.\n\n \n **\n You want to conflate mass and energy into one single entity called a 'mass-energy unit'. I consider a 'mass-energy unit' to be an arbitrarily devised measurement for the amount of energy required to affect an inertial quantity, a mass. Sort of like, 'foot-pound' or 'metre/gram'. A foot is not a pound, a metre is not a gram, and a quantum of mass is not a quantum of energy.", 
   {}, 
   250763, 
   null, 
   1171334160.0
  ], 
  [
   250837, 
   null, 
   "electrolyte", 
   "The 2LoT governs entropy. There is also no form of entropy that is not governed by the 2LoT.\n\n Please realize that wabbit has invented his own kind of \"entropy.\" While it seems almost as if he's talking about some sort of configurational entropy, his \"entropy\" can only be measured by quantifying the \"adaptedness\" of an organism to its environment. The second law of thermodynamics applies to his arbitrary meaning of \"entropy\" no more than it applies to gravity or mathematics.", 
   {}, 
   250760, 
   null, 
   1171334340.0
  ], 
  [
   250839, 
   null, 
   "Liminus", 
   "And waves as well, I suppose. After all, if you start out with an 'a priori' metaphysical assumption that everything is matter/mass, and nothing is not matter/mass, then what other conclusion can you lead yourself to?\n \n BTW, \"equivalent\" means 'equal to' in some particular aspect. Such as, that horse is equivalent to this cow wrt weight and grass-eating capacity. It does not mean that a horse is a cow. Force and energy may equate to matter in certains respects, but that does not at all make them the same thing.\n\n \n I will not get into an argument about definitions. Modern physics makes no distinction between matter and energy. See below:\n \n \nJust for fun, when you say, \"matter\", what do you mean by that word!\n\n \n Part of the problem is that using the term 'matter' forces an artificial distinction between traditional notions of 'matter' and 'energy' which is no longer relevant to modern physics. Unfortunately, in order to explain this irrelevance, we find ourselves (as I have) using the very word that caused the problem.\n \n If we are to be utterly precise when talking about the stuff of reality, we would have to start talking in terms of fermions (the particles which make up what is traditionally, and colloquially, termed 'matter') and bosons (the particles associated with forces).\n \n You are trying to define an outmoded term which has been rendered redundant, due to its imprecision, by modern physics. This is not to say the term is not used in a general sense, but it is understood that it cannot be used with any accuracy or specificity.\n \n \nI do not see myself as confused, and yes, I am familiar with 'wave/particle duality', slit-experiments and whatnot. And I notice, before you were talking \"the identical nature of [particles] and energy\", so at least what I take to be your own confusion is abating somewhat. You're still trying to conflate cause with effect, however, when you claim that mass/inertia in an entity, and the force/energy needed to overcome it, are the exact same thing, and not simply equivalent to one another, as per my horse/cow example. And that is still utterly irrational.\n\n \n Inertia and force are human concepts imposed open the reality of what actually takes place for the purpose of ease of understanding. Any 'force' which overcomes inertia (and any other force for that matter) is reducible to the effects that fundamental mass-energy units have on one another due to their respective inherent quantites. \n \n The only force which has not been explained, both theoretically and experimentally, in this manner by particle physics is that of gravity, which as I said earlier may not be a force so much as a by-product of the nature of spacetime.\n \n \nSadly, you have failed to show any misunderstanding on my part, even though you keep repeating the same assertions over and over, without ever actually coming to grips with my objections to them, beyond some vague appeal to the authority of 'physics', whatever that is supposed to mean.\n\n \n Indeed I do not understand your objections, other than that they seem to me to originate in a worldview that is incompatible with modern physics.\n \n \nYou then threw in random agglomerations of gas molecules as if they constituted 'systems', \n\n \n They do. A cloud of gas is a physical system.\n \n \nand from that went to trying to explain a closed system, as per the 2LoT, in terms of its parts being two or more open systems, as an attempt to justify your assertion that the 2LoT allows for an increase in order, decrease in entropy, in a closed system; which it does not, in fact, do.\n\n \n Now we are back to the same old misunderstanding of the 2LoT. Of course it does not allow an overall decrease in entropy in a closed system. I have never said that it does. It allows for a local decrease in entropy as long as entropy increases somewhere else in that system. Hence my whole 'transfer of entropy' explanation which I will not repeat.\n \n \nWhat I have said, repeatedly, is that biosystems are open systems, those that input energy and generate new information in the form of novel complex structures and processes, or simply to maintain old ones, while outputting entropy as failed concepts, random mistakes, accidents-- i.e., disinformation.\n THat is, to input Vitality to internally generate and conserve meaning and significance, while ouputting [as entropy], senselessness and meaninglessness wrt the biosystem's own identity.\n \n The difference between us is that you base your understanding of biosystems on thermodynamics, and I base mine on semiotics.\n\n \n The problem with this is that 'failed', 'mistakes', 'accidents', 'meaning' and 'significance' are subjective and unmeasurable, whereas 'energy' and 'entropy' are objective and measurable.\n \n \n Another difference between us is that you maintain that all of the energy input into an open system comes in the form of massy particles, whereas I insist that mass and energy are equivalent, (in so far as it requires so much energy to effect a given mass to given degree), but that a 'mass' and the energy it carries, and inertia and the force needed to overcome it, are not at all identical entities...\n \n ...As above, 'equivalence' is NOT 'sameness'. What a thing is, is not the same as what it is equal to. Saying that my pair of aces equals your pair of aces is NOT saying that my pair of aces IS your pair of aces.\n \n And that is how equations, including the famous E=MCsquared, are meant to be interpreted.\n\n \n I believe I have covered this above.\n \n \n \nWrong. Two plates on a table is not a system. To be a system there needs must be interaction between parts in order to act as one whole. You can have a billion 'particles', from sub-atomic quanta to macroscopic bits of salt, and have no 'system' at all.\n\n \n Just like the two stumps, two plates are a system in that they exert a tiny gravitational pull on each other. This is a measurable interaction. \n \n \n \nWhat's there to grasp?!? No offense I hope, but you are not saying anything; you are just stringing words together. What's your point?!?!\n\n \n Careful. Hope all you want, but that was quite offensive. My point was yet another explanation of what order entails, the best of which so far has been the example of proteins. Read that one again.\n \n \n \nBy saying that everything is a system you have effectively rendered the word, 'system', meaningless, and the concept absurd.\n\n \n Makes perfect sense to me. All things in the universe are a part of one system or another, in fact usually part of multiple systems, all of which consist of smaller systems. This is hardly a radical or controversial statement.\n \n \nThe 'order' of a system is not a prerequisite for that system's existence. Once any system exists, it may then become ordered or disordered, depending on what happens, internally and externally to effect changes on that system.\n\n \n \nWhat can I say? To me, with apologies, this is sheer nonsense.\n\n \n I fail to see why. You suggested that something must be ordered for it to be a system, which is incorrect. As I just explained, everything is a part of a system. Some systems are relatively ordered, some relatively disordered. This can change over time. This potential change is governed by the 2LoT.\n \n \nOnce again, your assertions are not explanations. By 'structured/unstructered' I certainly do mean, 'ordered/disordered', and that 'systems' are ordered/structured and that non-systems, ie., simple agglomerates, confused and jumbled heaps or raw quantities of stuff, are not. I repeat--a system is not a system unless it is composed of a number of parts that interact with each other in an orderly fashion.\n\n \n What you call 'non-systems' are still considered systems in physics. The reason for this is that there is no black and white distinction between 'order' and 'disorder', there are only fine gradations of a system being ordered or disordered relative to any other system.\n Your terms 'agglomerate', 'confused', 'jumbled', and 'raw' have no meaning with regard to any acceptably precise description of a system.\n \n \nIt is a name for an effect, but it is not an explanation for that effect. What is the force that creates that effect? Apparently thermodynamics. What force drives thermodynamics? Gravity, electro-magnetism, strong and weak nuclear? Any ideas?\n\n \n Thermodynamics is not a process that needs to be 'driven'. Thermodynamics is a science which describes the very complex changes in temperature, pressure and volume in physical systems. These changes themselves are driven by the physical forces.", 
   {}, 
   250829, 
   null, 
   1171334880.0
  ], 
  [
   250840, 
   null, 
   "Liminus", 
   "There are only a few other points I feel worth replying to which will not involve me repeating myself:\n \n \nThe point is that they are not simply and only physical (mechanical) systems.\n\n \n Yet they can be fully understood with nothing more than physical laws.\n \n \nSo you are now saying that 'entropy' is an abstraction, a mere semantic label?\n That it is not a real and actual physical phenomenon?\n\n \n Of course not; you are reading something into my words which is not there. Entropy is, of course, a phenomenon. This whole part of our debate goes back to me trying to clarify that when I said entropy is 'transferred', I did not mean that a literal physical thing called 'entropy' moves from one place to another. \n \n \nInteresting word, \"to convert\". Basically it means to change something into something else. Something you could not do with mass and energy, i.e., 'converting ' the one into the other, if mass and energy were the same thing to begin with.\n\n \n They are two different forms of the same thing, much like ice, water and steam are three forms of the H2O molecule. Much as I fully intend to remain as polite as possible, I am growing exceedingly weary of your semantic arguments which have no bearing upon the observed facts of physical theory.\n \n \nEverything reduces to one thing, in the end. You say it reduces to 'mass'. I say it reduces to 'meaning'.\n\n \n Actually I would say it reduces to 'quanta'. Please explain what the 'meaning' of an electron is.\n \n \nI consider a 'mass-energy unit' to be an arbitrarily devised measurement for the amount of energy required to affect an inertial quantity, a mass.\n\n \n Then you are wrong. A 'mass-energy unit' is any fundamental particle (or quantum).", 
   {}, 
   250839, 
   null, 
   1171335840.0
  ], 
  [
   250841, 
   null, 
   "wascallywabbit", 
   "[quote]\nThere are only a few other points I feel worth replying to which will not involve me repeating myself:\n \n \n \n Yet they can be fully understood with nothing more than physical laws.\n \n \n \n Of course not; you are reading something into my words which is not there. Entropy is, of course, a phenomenon. This whole part of our debate goes back to me trying to clarify that when I said entropy is 'transferred', I did not mean that a literal physical thing called 'entropy' moves from one place to another. \n \n \n \n They are two different forms of the same thing, much like ice, water and steam are three forms of the H2O molecule. Much as I fully intend to remain as polite as possible, I am growing exceedingly weary of your semantic arguments which have no bearing upon the observed facts of physical theory.\n \n \n \n Actually I would say it reduces to 'quanta'. Please explain what the 'meaning' of an electron is.\n\n \n **\n Most of the above is simply repeated opinion. As to this last bit, an electron has no meaning because an electron, per se, is nothing but a datum, and meaning is that which arises in relations between data, not in data. That is why systems are information/meaning rich, while 'particles/quanta' are meaningless on their own.\n \n \n \n\n Then you are wrong. A 'mass-energy unit' is any fundamental particle (or quantum).\n\n \n **\n Well, it was fun while it lasted. No point continuing an 'is so, is not' exchange.\n \n Thanks.", 
   {}, 
   250840, 
   null, 
   1171336740.0
  ], 
  [
   251180, 
   null, 
   "wascallywabbit", 
   "**\n http://www.journals.royalsoc.ac.uk/(13fy5rzk1aflm5abybu0okq4)/app/home/contribution.asp?referrer=parent&backto=issue,14,14;journal,59,319;linkingpublicationresults,1:102024,1\n \n Obtaining multiple separate food sources: behavioural intelligence in the Physarum plasmodium\n \n \n Toshiyuki Nakagaki , Ryo Kobayashi A1, Yasumasa Nishiura A1, Tetsuo Ueda A1 \n \n A1 Research Institute for Electronic Science, Hokkaido University, Sapporo 060-0812, Japan\n A2 Creative Research Initiative 'Sousei', Hokkaido University, Sapporo 001-0021, Japan\n \n \n Abstract: \n \n \n To evaluate performance in a complex survival task, we studied the morphology of the Physarum plasmodium transportation network when presented with multiple separate food sources. The plasmodium comprises a network of tubular elements through which chemical nutrient, intracellular signals and the viscous body are transported and circulated. When three separate food sources were presented, located at the vertices of a triangle, the tubular network connected them via a short pathway, which was often analogous to the mathematically shortest route known as Steiner's minimum tree (SMT). The other common network shape had high fault tolerance against accidental disconnection of the tubes and was known as cycle (CYC). Pattern selection appeared to be a bistable system involving SMT and CYC. When more than three food sources were presented, the network pattern tended to be a patchwork of SMT and CYC. We therefore concluded that the plasmodium tube network is a well designed and intelligent system.", 
   {}, 
   250841, 
   null, 
   1171660380.0
  ], 
  [
   251185, 
   null, 
   "wascallywabbit", 
   "**\n \n Superorganisms: From Simplicity To Complexity\n Superorganisms are biological entities made up of large numbers of simpler entities that have banded together to perform functions they cannot do as individuals. Termite mounds are often mentioned as superoganisms. But here we examine colonies of organisms that are much simpler and much smaller than termites. \n What entices the anomalist to attend to superorganisms? Here are two of the several questions superorganisms raise. \n \n \n How do superorganisms evolve properties that its constituent individuals do not possess, such as mobility, unique sensors, and even a modicum of intelligence. \n Since superorganisms do not reproduce as superorganisms, how can natural selection operate on these superorganisms? \n Salps. Books dealing with the unexplained sometimes include a photograph of a huge marine creature identified as a sea monster. This famous photo is real and so is the monster in it. But this creature is not reptilian; it is really a salp, a colonial tunicate. Tunicates are tiny, primitive marine organisms usually classified as invertebrates. Some species of tunicates have somehow acquired the habit of aggregating in immense numbers to create long, hollow, snake-like tubes called \"salpa.\" Salps may reach lengths of 45 feet, with diameters of 3 feet. No wonder they are falsely identified as sea monsters. \n Structurally, the tunicates comprising the salp are embedded in a gelatinous wall facing inward. Each possesses a siphon that pumps nutrient-carrying sea water. Working in unison, the tunicates create a surprisingly strong current of sea water through the tube, and the salp becomes jet-propelled. \n \n Thus, we have a mobile monster, but no ship-swallowing leviathan. \n \n (Griffin, D.J.G., and Yaldwyn, J.C.; \"Giant Colonies of Pelagic Tunicates..,\" Nature, 226:464, 1970) \n \n Slime molds. Moving down life's ladder to even smaller and simpler organisms, some amoebas have a bizarre life cycle that ends as a superorganism called a \"slime mold.\" If you viewed an amoeba through the microscope in biology lab, you know that they are very tiny, very simple, and most certainly not very bright. But given enough food, some species of amoeba divide and keep dividing until they clump together in a \"slug\" that sends out streamers and sort of flows along the surface. We now have a mobile superorganism searching for food (mostly bacteria). Eventually, the moving colony of amoebas anchors itself. Some of the superorganism's cells specialize to create a stalk called a \"fruiting body.\" The amoebas in the fruiting body change into spores and are wafted away on the wind. In this way, the simple, lowly amoebas are transformed into a radically different entity. One wonders how this superorganism, this slime mold, is controlled. Where are its sensors and its information processing center, if it possesses one? \n \n (Stewart, Ian; \"Spiral Slime,\" Scientific American, 283:116, November 2000.) \n \n This question becomes more difficult to answer when we learn that slime molds can display rudimentary intelligence in the sense that they can solve mazes in their search for food. They are not as clever as rats, but they do optimize their travels through the maze. \n \n (Nakagaki, Toahiyuki, et al; \"Maze-Solving by an Amoeboid Organism,\" Nature, 407:470, 2000.) \n \n Biofilms. Down near the bottom of life's ladder dwell the bacteria. Their genomes must be miniscule and gray matter is not to be found. Nevertheless, some bacteria band together to form biofilms. Biofilms are three-dimensional, complex structures composed of innumerable, specialized bacteria all working together. W. Costerton at Montana State University imagines what a biofilm would look like if one were bacterium-size. \n \n \n If you found yourself in a biofilm, you'd be going along a channel full of water, like the canals in Venice, and up from the bottom of the channel, on either side, would be these slime towers. The channels would be bringing in oxygen and nutrients. and removing waste. And within each building, so to speak, some of the bacteria would be cooperating with each other, making one compound and passing it along to the next. It's at least as complicated as a tissue. and possibly as a city. \n (Chicurel, Marina; \"Slimebusters.\" Nature, 408:284, 2000.) \n \n Comment. Since bacteria have no brains, where do the building plans of this \"city\" reside? \n \n Nanocrystal aggregates. Even lifeless nanocrystals spontaneously form long, oriented chains. Self-organization is common in inorganic nature. Nanocrystals are clumps of atoms numbering in the hundreds, often thousands. Typically, nanocrystals are only 1-10 nano-meters long. Even so, they have a colonial spirit, and, like the tunicates and amoebas, they aggregate and self-organize. \n \n ((Alivisatos, A.P.; \"Naturally Aligned Nanocrystals,\" Science, 289:736, 2000.) \n \n Comment. Sometimes that vaunted chasm separating life from non-life seems pretty narrow! [comment meretricious--ww]\n \n \n From Science Frontiers #133, JAN-FEB 2001. &#169; 2001 William R. Corliss\n \n http://www.science-frontiers.com/sf133/sf133p08.htm", 
   {}, 
   251180, 
   null, 
   1171661220.0
  ], 
  [
   251200, 
   null, 
   "wascallywabbit", 
   "**\n For interest's sake--\n http://www.billbrouard.com/intelligence.htm", 
   {}, 
   251185, 
   null, 
   1171664880.0
  ]
 ], 
 {}, 
 {
  "title": "4Forums.com Political Debates and Polls -  Intelligent evolution--Semiotics and the \"Baldwin effect\".", 
  "url": "http://www.4forums.com/political/creation-intelligent-design-vs-evolution/9535-intelligent-evolution-semiotics-baldwin-effect.html", 
  "breadcrumbs": [
   "Creation(Intelligent Design) vs Evolution"
  ], 
  "id_number": 9535, 
  "discussion_files": [
   [
    "20317.html", 
    "http://www.4forums.com/political/creation-intelligent-design-vs-evolution/9535-intelligent-evolution-semiotics-baldwin-effect-print.html"
   ], 
   [
    "20318.html", 
    "http://www.4forums.com/political/creation-intelligent-design-vs-evolution/9535-intelligent-evolution-semiotics-baldwin-effect-5-print.html"
   ], 
   [
    "20319.html", 
    "http://www.4forums.com/political/creation-intelligent-design-vs-evolution/9535-intelligent-evolution-semiotics-baldwin-effect-4-print.html"
   ], 
   [
    "20320.html", 
    "http://www.4forums.com/political/creation-intelligent-design-vs-evolution/9535-intelligent-evolution-semiotics-baldwin-effect-3-print.html"
   ], 
   [
    "20321.html", 
    "http://www.4forums.com/political/creation-intelligent-design-vs-evolution/9535-intelligent-evolution-semiotics-baldwin-effect-2-print.html"
   ]
  ], 
  "identifier": 9535
 }
]